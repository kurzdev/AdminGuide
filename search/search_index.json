{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This Admin Guide describes how I setup my servers using docker. Installation \u00b6 I created a script which can be executed to setup the server. I suggest you to get used to my structure (e.g. the stack logic), otherwise you might run into problems later on. If you never used this guide, you should perform the installation manually to understand the structure. Post Installation Script You can basicly skip most of the installation section, but there are some exceptions. First you should create all user accounts, and ensure that everyone is able to authenticate using public key authentication. You can add the users in the configuration section of the `postinstall.sh` to give them the groups, aliases, ... After you are sure that you can connect to the server you should secure your ssh server (e.g. disallow authentication using passwords, root login, ...). If you want to change your hostname to something cooler than the name your hoster assigned you (this is not required, I do it to improve the identification process of the server, that I'm connected to). You also need to setup your dns records, consider to change the name servers to cloudflare if you have trouble with the dns challenge for wildcard certificate later on. curl -fsSL https://raw.githubusercontent.com/felbinger/AdminGuide/master/postinstall.sh | sudo bash Create your Services \u00b6 After you successfully installed your system, you can add the services you need. Before you add a new service think which stack fits best. It might be useful to create a new stack. You can find a lot of services (e.g. Databases, Gameserver, Apps for Communication, Apps for File Storage, ...) in the navigation bar on the left side of the page. Simply add them to your docker-compose.yml and modify the required attributes (e.g. passwords, domain name, routing configuration, ...). Tools \u00b6 ctop \u00b6 Simple commandline monitoring tool for docker containers: sudo wget https://github.com/bcicen/ctop/releases/download/v0.7.3/ctop-0.7.3-linux-amd64 \\ -O /usr/local/bin/ctop sudo chmod +x /usr/local/bin/ctop Docker Network Viewer \u00b6 A simple tool to show docker networks: sudo wget https://github.com/felbinger/DNV/releases/download/v0.1/dnv \\ -O /usr/local/bin/dnv sudo chmod +x /usr/local/bin/dnv $ sudo ./dnv bridge 172 .17.0.0/16 proxy 192 .168.0.0/24 database 192 .168.1.0/24 monitoring 192 .168.2.0/24 main 192 .168.100.0/24 storage 192 .168.101.0/24 comms 192 .168.102.0/24 jitsi 192 .168.103.0/24 games 192 .168.104.0/24 Backup \u00b6 I suspended all file backup projects ( GBM , PyBackup ). I suggest you use borg backup for file backups. You can use my DBM to get the database backups from your docker container. Docker Backup Manager (DBM) \u00b6 The docker backup management is a docker image to back up the database and ldap server inside your docker container. It's basicly a bash script which uses the docker network to access the database servers. You can simply create a script which runs the container with the required environment variables to create the backup. Security Warning Note that all scripts executed by a root cronjob, should only be editable by root. Otherwise a lower privileged user, might be able to gain higher privileges ( Privilege Escalation ). You're script may look like this, you may remove the environmentment variables you don't need. #!/bin/bash docker run --rm -it \\ -v '/var/backups/:/data/' \\ -e \"LDAP_HOST=main_ldap_1\" \\ -e \"LDAP_BASE_DN=dc=domain,dc=de\" \\ -e \"LDAP_BIND_DN=cn=admin,dc=domain,dc=de\" \\ -e \"LDAP_BIND_PW=S3cr3T\" \\ -e \"MARIADB_HOST=main_mariadb_1\" \\ -e \"MARIADB_DATABASES=mysql mariadb_backup nonexistent\" \\ -e \"MARIADB_PASSWORD=S3cr3T\" \\ -e \"MARIADB_USERNAME=root\" \\ -e \"POSTGRES_HOST=main_postgres_1\" \\ -e \"POSTGRES_USERNAME=postgres\" \\ -e \"POSTGRES_PASSWORD=S3cr3T\" \\ -e \"POSTGRES_DATABASES=postgres_backup postgres nonexistent\" \\ -e \"MONGODB_HOST=main_mongo_1\" \\ -e \"MONGODB_PASSWORD=S3cr3T\" \\ -e \"MONGODB_DATABASES=admin nonexistent\" \\ --network = database \\ ghcr.io/felbinger/dbm I really suggest creating a separate database user which can only create backups. Checkout the documentation for your dbms: If you created these users for the old backup (eighter pybackup or gbm), you probally limited these users to the localhost. The DBM creates the backup over the network, so it can't use a user which is limited to localhost. Make sure to adjust the privileges. MariaDB # example for mariadb (you need SELECT and LOCK TABLES permissions) $ sudo docker-compose exec mariadb mysql -u root -pS3cr3T mariadb> CREATE USER 'backup' @ '%' IDENTIFIED BY 'secret_password_for_backup_user' ; mariadb> GRANT SELECT, LOCK TABLES ON mysql.* TO 'backup' @ 'localhost' ; # add privileges to all databases that you want to backup! mariadb> FLUSH PRIVILEGES ; mariadb> EXIT ; PostgreSQL MongoDB Backups should also be scheduled using cronjob: # database backups using docker backup management every three hours 0 */3 * * * /bin/bash /root/db_backup.sh >/dev/null 2>&1 Borg Backup \u00b6 Like I mentioned above, I'm currently using borg for file backups. Checkout the official documentation I created a script to perform the backups: #!/bin/bash export BORG_PASSPHRASE = \"<your_borg_repository_passphrase>\" # date in format: YYYY-MM-DD_HH-MM round to 15 minutes blocks DATE = $( date + \"%Y-%m-%d_%H\" ) - $( echo \" $( date +%M ) - ( $( date +%M ) %15)\" | bc ) PATHS =( \"/srv/\" \"/home/admin/\" \"/root/\" \"/etc/ssh/sshd_config\" \"/etc/telegraf/telegraf.conf\" ) borg create --stats --progress -C lzma,5 /home/borg:: ${ DATE } ${ PATHS [@] } The script is being executed by a crontab every night: # run borg backup at 4 am 0 4 * * * /bin/bash /root/backup.sh >/dev/null 2>&1 I also created a script to pack the whole borg repository into a tar file: #!/bin/bash export BORG_PASSPHRASE = \"<your_borg_repository_passphrase>\" latest = $( borg list /home/borg | tail -1 | cut -d \" \" -f 1 ) # extract last full backup from repository #borg export-tar --progress \"/home/borg::${latest}\" \"/home/user/${latest}.tar\" # validate that bork is not in use while [[ -n $( pidof -x $( which borg )) ]] ; do sleep 60 done # pack backup repository tar -cvf /home/user/backup_repository.tar /home/borg chown user:user /home/user/backup_repository.tar chmod 664 /home/user/backup_repository.tar","title":"Overview"},{"location":"#installation","text":"I created a script which can be executed to setup the server. I suggest you to get used to my structure (e.g. the stack logic), otherwise you might run into problems later on. If you never used this guide, you should perform the installation manually to understand the structure. Post Installation Script You can basicly skip most of the installation section, but there are some exceptions. First you should create all user accounts, and ensure that everyone is able to authenticate using public key authentication. You can add the users in the configuration section of the `postinstall.sh` to give them the groups, aliases, ... After you are sure that you can connect to the server you should secure your ssh server (e.g. disallow authentication using passwords, root login, ...). If you want to change your hostname to something cooler than the name your hoster assigned you (this is not required, I do it to improve the identification process of the server, that I'm connected to). You also need to setup your dns records, consider to change the name servers to cloudflare if you have trouble with the dns challenge for wildcard certificate later on. curl -fsSL https://raw.githubusercontent.com/felbinger/AdminGuide/master/postinstall.sh | sudo bash","title":"Installation"},{"location":"#create-your-services","text":"After you successfully installed your system, you can add the services you need. Before you add a new service think which stack fits best. It might be useful to create a new stack. You can find a lot of services (e.g. Databases, Gameserver, Apps for Communication, Apps for File Storage, ...) in the navigation bar on the left side of the page. Simply add them to your docker-compose.yml and modify the required attributes (e.g. passwords, domain name, routing configuration, ...).","title":"Create your Services"},{"location":"#tools","text":"","title":"Tools"},{"location":"#ctop","text":"Simple commandline monitoring tool for docker containers: sudo wget https://github.com/bcicen/ctop/releases/download/v0.7.3/ctop-0.7.3-linux-amd64 \\ -O /usr/local/bin/ctop sudo chmod +x /usr/local/bin/ctop","title":"ctop"},{"location":"#docker-network-viewer","text":"A simple tool to show docker networks: sudo wget https://github.com/felbinger/DNV/releases/download/v0.1/dnv \\ -O /usr/local/bin/dnv sudo chmod +x /usr/local/bin/dnv $ sudo ./dnv bridge 172 .17.0.0/16 proxy 192 .168.0.0/24 database 192 .168.1.0/24 monitoring 192 .168.2.0/24 main 192 .168.100.0/24 storage 192 .168.101.0/24 comms 192 .168.102.0/24 jitsi 192 .168.103.0/24 games 192 .168.104.0/24","title":"Docker Network Viewer"},{"location":"#backup","text":"I suspended all file backup projects ( GBM , PyBackup ). I suggest you use borg backup for file backups. You can use my DBM to get the database backups from your docker container.","title":"Backup"},{"location":"#docker-backup-manager-dbm","text":"The docker backup management is a docker image to back up the database and ldap server inside your docker container. It's basicly a bash script which uses the docker network to access the database servers. You can simply create a script which runs the container with the required environment variables to create the backup. Security Warning Note that all scripts executed by a root cronjob, should only be editable by root. Otherwise a lower privileged user, might be able to gain higher privileges ( Privilege Escalation ). You're script may look like this, you may remove the environmentment variables you don't need. #!/bin/bash docker run --rm -it \\ -v '/var/backups/:/data/' \\ -e \"LDAP_HOST=main_ldap_1\" \\ -e \"LDAP_BASE_DN=dc=domain,dc=de\" \\ -e \"LDAP_BIND_DN=cn=admin,dc=domain,dc=de\" \\ -e \"LDAP_BIND_PW=S3cr3T\" \\ -e \"MARIADB_HOST=main_mariadb_1\" \\ -e \"MARIADB_DATABASES=mysql mariadb_backup nonexistent\" \\ -e \"MARIADB_PASSWORD=S3cr3T\" \\ -e \"MARIADB_USERNAME=root\" \\ -e \"POSTGRES_HOST=main_postgres_1\" \\ -e \"POSTGRES_USERNAME=postgres\" \\ -e \"POSTGRES_PASSWORD=S3cr3T\" \\ -e \"POSTGRES_DATABASES=postgres_backup postgres nonexistent\" \\ -e \"MONGODB_HOST=main_mongo_1\" \\ -e \"MONGODB_PASSWORD=S3cr3T\" \\ -e \"MONGODB_DATABASES=admin nonexistent\" \\ --network = database \\ ghcr.io/felbinger/dbm I really suggest creating a separate database user which can only create backups. Checkout the documentation for your dbms: If you created these users for the old backup (eighter pybackup or gbm), you probally limited these users to the localhost. The DBM creates the backup over the network, so it can't use a user which is limited to localhost. Make sure to adjust the privileges. MariaDB # example for mariadb (you need SELECT and LOCK TABLES permissions) $ sudo docker-compose exec mariadb mysql -u root -pS3cr3T mariadb> CREATE USER 'backup' @ '%' IDENTIFIED BY 'secret_password_for_backup_user' ; mariadb> GRANT SELECT, LOCK TABLES ON mysql.* TO 'backup' @ 'localhost' ; # add privileges to all databases that you want to backup! mariadb> FLUSH PRIVILEGES ; mariadb> EXIT ; PostgreSQL MongoDB Backups should also be scheduled using cronjob: # database backups using docker backup management every three hours 0 */3 * * * /bin/bash /root/db_backup.sh >/dev/null 2>&1","title":"Docker Backup Manager (DBM)"},{"location":"#borg-backup","text":"Like I mentioned above, I'm currently using borg for file backups. Checkout the official documentation I created a script to perform the backups: #!/bin/bash export BORG_PASSPHRASE = \"<your_borg_repository_passphrase>\" # date in format: YYYY-MM-DD_HH-MM round to 15 minutes blocks DATE = $( date + \"%Y-%m-%d_%H\" ) - $( echo \" $( date +%M ) - ( $( date +%M ) %15)\" | bc ) PATHS =( \"/srv/\" \"/home/admin/\" \"/root/\" \"/etc/ssh/sshd_config\" \"/etc/telegraf/telegraf.conf\" ) borg create --stats --progress -C lzma,5 /home/borg:: ${ DATE } ${ PATHS [@] } The script is being executed by a crontab every night: # run borg backup at 4 am 0 4 * * * /bin/bash /root/backup.sh >/dev/null 2>&1 I also created a script to pack the whole borg repository into a tar file: #!/bin/bash export BORG_PASSPHRASE = \"<your_borg_repository_passphrase>\" latest = $( borg list /home/borg | tail -1 | cut -d \" \" -f 1 ) # extract last full backup from repository #borg export-tar --progress \"/home/borg::${latest}\" \"/home/user/${latest}.tar\" # validate that bork is not in use while [[ -n $( pidof -x $( which borg )) ]] ; do sleep 60 done # pack backup repository tar -cvf /home/user/backup_repository.tar /home/borg chown user:user /home/user/backup_repository.tar chmod 664 /home/user/backup_repository.tar","title":"Borg Backup"},{"location":"installation/","text":"Base \u00b6 First we update the package lists, kernel and other distribution specific stuff. Then we install some tools that are needed for this guide. apt-get update apt-get -y dist-upgrade apt-get -y install apt sudo curl nano Change Hostname [optional] \u00b6 In most cases, your hosting provider gave your machine an ugly hostname. Just change it in the files /etc/hostname and /etc/hosts to your new one according to the following example: # /etc/hostname <hostname> # /etc/hosts 127 .0.0.1 localhost 127 .0.1.1 <fqdn.domain.tld> <hostname> # <-- <ipv4> <fqdn.domain.tld> <hostname> # <-- # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters IPv6-FQDN is missing, although I never set up a server using ipv6. In this case I decided to use the hostname server and assign the fully qualified domain name fqdn.domain.tld to it. To apply the changes, you need to restart the server. The Admin Group \u00b6 On every server that is managed by me, there exists an admin group that has access to almost all service configuration files. This group is used to easily manage multiple administrators on one server. groupadd -g 997 admin mkdir /home/admin chown -R root:admin /home/admin chmod -R 775 /home/admin Create Users \u00b6 You should create at least one user, and use it instead of the root user. Let's create a new user called user and add him to the groups sudo and admin . default adduser user usermod -aG sudo,admin user any adduser <user> usermod -aG sudo,admin <user> You can repeat this part for any other user who needs administrative access. Setup SSH Keys \u00b6 SSH keys are a fundamental for secure connection to your server. Create SSH Keys \u00b6 If you don't already have an SSH Key it is recommended to create one: rsa ssh-keygen -t rsa dsa ssh-keygen -t dsa ecdsa ssh-keygen -t ecdsa ed25519 ssh-keygen -t ed25519 other # a list off all types, witch are supportet by your system: (second line) ssh-keygen -h ssh-keygen -t <type> Setup SSH Keys on the server \u00b6 There are multiple options to add your public keys to the file ~/.ssh/authorized_keys : Client Side One option is to use ssh-copy-id on the client machine (and authenticate yourself with for example a password), and the ssh client automatically copy the keys there. default key ssh-copy-id <user>@<ip> specific key ssh-copy-id -i <keyfile> <user>@<ip> ssh-copy-id uses the description of your public key. Server Side Another options is to append your public key manually to the ~/.ssh/authorized_keys file in the following format ssh-<type> <public_key> [description] : rsa echo \"ssh-rsa <key> [description]\" >> ~/.ssh/authorized_keys dsa echo \"ssh-dsa <key> [description]\" >> ~/.ssh/authorized_keys ecdsa echo \"ssh-ecdsa <key> [description]\" >> ~/.ssh/authorized_keys ed25519 echo \"ssh-ed25519 <key> [description]\" >> ~/.ssh/authorized_keys other echo \"ssh-<type> <key> [description]\" >> ~/.ssh/authorized_keys Note that you must be logged in as the user for whom the SSH key will be added. Securing the SSH Server \u00b6 After we successfully logged in using one of our user accounts, we can reconfigure ssh. We set the following values: # /etc/ssh/sshd_config # disallow authentication with passwords PasswordAuthentication no # disallow login via root PermitRootLogin no # maximum number of authentication attempts MaxAuthTries 3 # maximum number of sessions of one user that can be logged in at the same time MaxSessions 5 Don't forget to restart your SSH Server: sudo systemctl restart ssh Make sure you can log in using your SSH private key, otherwise you are not able to login again after the next step!","title":"Base"},{"location":"installation/#base","text":"First we update the package lists, kernel and other distribution specific stuff. Then we install some tools that are needed for this guide. apt-get update apt-get -y dist-upgrade apt-get -y install apt sudo curl nano","title":"Base"},{"location":"installation/#change-hostname-optional","text":"In most cases, your hosting provider gave your machine an ugly hostname. Just change it in the files /etc/hostname and /etc/hosts to your new one according to the following example: # /etc/hostname <hostname> # /etc/hosts 127 .0.0.1 localhost 127 .0.1.1 <fqdn.domain.tld> <hostname> # <-- <ipv4> <fqdn.domain.tld> <hostname> # <-- # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters IPv6-FQDN is missing, although I never set up a server using ipv6. In this case I decided to use the hostname server and assign the fully qualified domain name fqdn.domain.tld to it. To apply the changes, you need to restart the server.","title":"Change Hostname [optional]"},{"location":"installation/#the-admin-group","text":"On every server that is managed by me, there exists an admin group that has access to almost all service configuration files. This group is used to easily manage multiple administrators on one server. groupadd -g 997 admin mkdir /home/admin chown -R root:admin /home/admin chmod -R 775 /home/admin","title":"The Admin Group"},{"location":"installation/#create-users","text":"You should create at least one user, and use it instead of the root user. Let's create a new user called user and add him to the groups sudo and admin . default adduser user usermod -aG sudo,admin user any adduser <user> usermod -aG sudo,admin <user> You can repeat this part for any other user who needs administrative access.","title":"Create Users"},{"location":"installation/#setup-ssh-keys","text":"SSH keys are a fundamental for secure connection to your server.","title":"Setup SSH Keys"},{"location":"installation/#create-ssh-keys","text":"If you don't already have an SSH Key it is recommended to create one: rsa ssh-keygen -t rsa dsa ssh-keygen -t dsa ecdsa ssh-keygen -t ecdsa ed25519 ssh-keygen -t ed25519 other # a list off all types, witch are supportet by your system: (second line) ssh-keygen -h ssh-keygen -t <type>","title":"Create SSH Keys"},{"location":"installation/#setup-ssh-keys-on-the-server","text":"There are multiple options to add your public keys to the file ~/.ssh/authorized_keys : Client Side One option is to use ssh-copy-id on the client machine (and authenticate yourself with for example a password), and the ssh client automatically copy the keys there. default key ssh-copy-id <user>@<ip> specific key ssh-copy-id -i <keyfile> <user>@<ip> ssh-copy-id uses the description of your public key. Server Side Another options is to append your public key manually to the ~/.ssh/authorized_keys file in the following format ssh-<type> <public_key> [description] : rsa echo \"ssh-rsa <key> [description]\" >> ~/.ssh/authorized_keys dsa echo \"ssh-dsa <key> [description]\" >> ~/.ssh/authorized_keys ecdsa echo \"ssh-ecdsa <key> [description]\" >> ~/.ssh/authorized_keys ed25519 echo \"ssh-ed25519 <key> [description]\" >> ~/.ssh/authorized_keys other echo \"ssh-<type> <key> [description]\" >> ~/.ssh/authorized_keys Note that you must be logged in as the user for whom the SSH key will be added.","title":"Setup SSH Keys on the server"},{"location":"installation/#securing-the-ssh-server","text":"After we successfully logged in using one of our user accounts, we can reconfigure ssh. We set the following values: # /etc/ssh/sshd_config # disallow authentication with passwords PasswordAuthentication no # disallow login via root PermitRootLogin no # maximum number of authentication attempts MaxAuthTries 3 # maximum number of sessions of one user that can be logged in at the same time MaxSessions 5 Don't forget to restart your SSH Server: sudo systemctl restart ssh Make sure you can log in using your SSH private key, otherwise you are not able to login again after the next step!","title":"Securing the SSH Server"},{"location":"installation/dns/","text":"Required DNS entries \u00b6 # redirect your domain to IPv4 @ A <ipv4> # redirect your domain to IPv6 (optional) @ AAAA <ipv6> # redirect all subdomains to IPv4 * A <ipv4> # redirect all subdomains to IPv6 (optional) * AAAA <ipv6> # redirect some subdomains to other IPv4 (optional) <subdomain> A <ipv4> # redirect some subdomains to other IPv6 (optional) <subdomain> AAAA <ipv4> # allow letsencrypt.org to issue certificates for your domain @ CAA 0 issue \"letsencrypt.org\" # allow letsencrypt.org to also issue wildcard certificates for your domain @ CAA 0 issuewild \"letsencrypt.org\" # set email address for policy violations @ CAA 0 iodef \"mailto:monitoring@domain.tld\" Cloudflare Name Servers \u00b6 It is recommended to change the name servers of your domain to the Cloudflare name servers. Check out this (support.cloudflare.com) tutorial for your provider. Example records for the Cloudflare DNS management: \u00b6 Configure reverse DNS \u00b6 The reverse DNS is used to obtain the domain attached to an IP address. You can do this in the server control panel. Validate DNS updates \u00b6 DNS Updates can take quiet some time! Check IPv4 DNS entries $ dig A <domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> A domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 55520 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;domain.tld. IN A ;; ANSWER SECTION: domain.tld. 300 IN A <ipv4 of your server> ;; Query time: 60 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:43:35 CET 2020 ;; MSG SIZE rcvd: 54 Check wildcard DNS entries $ dig A nonexisting.<domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> A nonexisting.domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 49020 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;nonexisting.domain.tld. IN A ;; ANSWER SECTION: nonexisting.domain.tld. 295 IN A <ipv4 of your server> ;; Query time: 30 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:48:11 CET 2020 ;; MSG SIZE rcvd: 65 Check CAA DNS entries $ dig CAA <domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> CAA domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 22461 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 7, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;domain.tld. IN CAA ;; ANSWER SECTION: domain.tld. 300 IN CAA 0 iodef \"mailto:monitoring@domain.tld\" domain.tld. 300 IN CAA 0 issue \"letsencrypt.org\" domain.tld. 300 IN CAA 0 issuewild \"letsencrypt.org\" ;; Query time: 30 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:45:38 CET 2020 ;; MSG SIZE rcvd: 283 Check reverse DNS $ nslookup <ip> reversed-ip.in-addr.arpa name = domain.tld. Authoritative answers can be found from:","title":"Configure DNS"},{"location":"installation/dns/#required-dns-entries","text":"# redirect your domain to IPv4 @ A <ipv4> # redirect your domain to IPv6 (optional) @ AAAA <ipv6> # redirect all subdomains to IPv4 * A <ipv4> # redirect all subdomains to IPv6 (optional) * AAAA <ipv6> # redirect some subdomains to other IPv4 (optional) <subdomain> A <ipv4> # redirect some subdomains to other IPv6 (optional) <subdomain> AAAA <ipv4> # allow letsencrypt.org to issue certificates for your domain @ CAA 0 issue \"letsencrypt.org\" # allow letsencrypt.org to also issue wildcard certificates for your domain @ CAA 0 issuewild \"letsencrypt.org\" # set email address for policy violations @ CAA 0 iodef \"mailto:monitoring@domain.tld\"","title":"Required DNS entries"},{"location":"installation/dns/#cloudflare-name-servers","text":"It is recommended to change the name servers of your domain to the Cloudflare name servers. Check out this (support.cloudflare.com) tutorial for your provider.","title":"Cloudflare Name Servers"},{"location":"installation/dns/#example-records-for-the-cloudflare-dns-management","text":"","title":"Example records for the Cloudflare DNS management:"},{"location":"installation/dns/#configure-reverse-dns","text":"The reverse DNS is used to obtain the domain attached to an IP address. You can do this in the server control panel.","title":"Configure reverse DNS"},{"location":"installation/dns/#validate-dns-updates","text":"DNS Updates can take quiet some time! Check IPv4 DNS entries $ dig A <domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> A domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 55520 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;domain.tld. IN A ;; ANSWER SECTION: domain.tld. 300 IN A <ipv4 of your server> ;; Query time: 60 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:43:35 CET 2020 ;; MSG SIZE rcvd: 54 Check wildcard DNS entries $ dig A nonexisting.<domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> A nonexisting.domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 49020 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;nonexisting.domain.tld. IN A ;; ANSWER SECTION: nonexisting.domain.tld. 295 IN A <ipv4 of your server> ;; Query time: 30 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:48:11 CET 2020 ;; MSG SIZE rcvd: 65 Check CAA DNS entries $ dig CAA <domain> @1.1.1.1 ; <<>> DiG 9.16.1-Ubuntu <<>> CAA domain.tld @1.1.1.1 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 22461 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 7, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;domain.tld. IN CAA ;; ANSWER SECTION: domain.tld. 300 IN CAA 0 iodef \"mailto:monitoring@domain.tld\" domain.tld. 300 IN CAA 0 issue \"letsencrypt.org\" domain.tld. 300 IN CAA 0 issuewild \"letsencrypt.org\" ;; Query time: 30 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Thu Nov 05 21:45:38 CET 2020 ;; MSG SIZE rcvd: 283 Check reverse DNS $ nslookup <ip> reversed-ip.in-addr.arpa name = domain.tld. Authoritative answers can be found from:","title":"Validate DNS updates"},{"location":"installation/docker/","text":"Old Docker Versions Older versions of the Docker binary were called docker or docker-engine or docker-io If you already installed this version you can uninstall it via: sudo apt-get remove docker docker-engine docker.io containerd runc Docker itself already provides a very good script: curl -fsSL https://get.docker.com | sudo bash Finally, you need to install Docker Compose: sudo curl -L -o /usr/local/bin/docker-compose \\ \"https://github.com/docker/compose/releases/latest/download/docker-compose- $( uname -s ) - $( uname -m ) \" sudo chmod +x /usr/local/bin/docker-compose On an ARM Maschine you need: pip install docker-compose Instead of typing sudo docker-compose up -d all the time you can use this alias and type dc up -d : echo 'alias dc=\"sudo docker-compose \"' >> ~/.bashrc Parts of the PostInstall script covered in this chapter #!/bin/bash function install_docker_compose () { curl -L \"https://github.com/docker/compose/releases/download/latest/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose } function docker_network_create () { name = ${ 1 } subnet = ${ 2 } docker network inspect ${ name } >/dev/null 2 > & 1 || \\ docker network create --subnet ${ subnet } ${ name } } # install docker if not already installed if [[ -z $( which docker ) ]] ; then if [[ -z $( which curl ) ]] ; then apt-get install curl fi curl https://get.docker.com | bash fi # install docker-compose if not already installed if [[ -z $( which docker-compose ) ]] ; then install_docker_compose fi","title":"Docker"},{"location":"installation/stack-logic/","text":"We will group the services in different \"stacks\" to manage them, this way we can change specific things without taking all services offline. Furthermore, we will use one docker network per stack to ensure, that each container is only able to communicate with other containers which it really needs. Getting Started \u00b6 First, let's add the default directories into the admin directory: mkdir -p /home/admin/ { services,images,tools,docs } / name description services contains the docker-compose and .env files images contains the data for custom docker images tools contains various tools docs contains the documentations of you server For each stack we will create, we want to have a directory in /home/admin/services/ , /home/admin/images/ and /srv/ : The directory in /home/admin/services/ contains the docker-compose.yml and .env files. Which is later used in the docker-compose.yml as env_file . The directory in /home/admin/images/ contains the source files for the docker image if we have to build the image on the server. The directory in /srv/ is used to store persistent data for the stack (docker volumes). We will also create multiple docker networks, to give the containers the ability to communicate with each other. Helper networks for specific communication (e.g. to the reverse proxy, the databases or the monitoring) start at 192.168.0.0/24 . Stack networks (one network for each stack) start at 192.168.100.0/24 . Note that a network with the submask 255.255.255.0 (cidr notation is 24) can only contain 254 hosts. You have to adjust your network size to your needs. Remember the formular: \\(2^{32-x}-2\\) where \\(x\\) is your submask in cidr notation (e.g. with \\(24\\) : \\(2^{32\u221224}\u22122=254\\) ; or with \\(20\\) : \\(2^{32\u221220}\u22122=4094\\) usable adresses) Name Subnet Usage Proxy 192.168.0.0/24 Container communication to nginx reverse proxy. Database 192.168.1.0/24 Communication to databases (MariaDB, MongoDB, PostgreSQL). Monitoring 192.168.2.0/24 Communication to monitoring utilities (InfluxDB). Main 192.168.100.0/24 Network for the Main Stack # create main stack name = 'main' mkdir -p \"/home/admin/{services,images}/ ${ name } /\" sudo mkdir -p \"/srv/ ${ name } /\" sudo docker network create --subnet 192 .168.100.0/24 ${ name } # create helper networks (we will need them in the next chapter) sudo docker network create --subnet 192 .168.0.0/24 proxy sudo docker network create --subnet 192 .168.1.0/24 database sudo docker network create --subnet 192 .168.2.0/24 monitoring You can create as many stacks, as you need. The main stack contains the services that are relevant for the majority of the services (e.g. reverse proxy, static webserver for the reverse proxy, databases, admin panels (because they are related to the databases), monitoring). All other services will be outsourced to another stack. The following list containers just a few ideas, how you could name them: games: all game servers (e.g. Minecraft, Arma 3) storage: applications that store your data (e.g. NextCloud, Syncthing, ...) comms (short form of communication): things to communicate (e.g. TeamSpeak, Sinusbot, Telegram Bots, Discord Bots) jitsi: another video conference system (simply use their configuration on github ) Lastly we are going to create a docker-compose.yml which we will use to define our networks. version : \"3\" services : ... # you need to add your services right here... networks : default : external : name : main proxy : external : name : proxy database : external : name : database monitoring : external : name : monitoring The network created for a particular stack will be called default in the matching docker-compose.yml . This will help us, because if we do not specify a network in the service sections of the docker-compose.yml , these services will automatically connect network default . Parts of the PostInstall script covered in this chapter #!/bin/bash ## CONFIGURATION ### ADM_NAME = 'admin' ADM_GID = 997 ADM_HOME = '/home/admin' ADM_USERS =( 'user' ) declare -A STACKS =( \\ [ \"main\" ]= \"192.168.100.0/24\" ) declare -A HELPER =( \\ [ \"proxy\" ]= \"192.168.0.0/24\" \\ [ \"database\" ]= \"192.168.1.0/24\" \\ [ \"monitoring\" ]= \"192.168.2.0/24\" ) ### END of CONFIGURATION ### function docker_network_create () { name = ${ 1 } subnet = ${ 2 } docker network inspect ${ name } >/dev/null 2 > & 1 || \\ docker network create --subnet ${ subnet } ${ name } } function create_compose () { compose = ${ 1 } touch ${ compose } echo -e \"version: '3.8'\\n\" > ${ compose } # define services echo -e \"services:\\n\" >> ${ compose } if [[ ${# SERVICES } == 0 ]] ; then echo -e \" test:\" >> ${ compose } echo -e \" image: hello-world\\n\" >> ${ compose } fi echo -e \"\\n\" >> ${ compose } # define networks echo -e \"networks:\" >> ${ compose } # define stack network echo -e \" default:\" >> ${ compose } echo -e \" external:\" >> ${ compose } echo -e \" name: ${ name } \" >> ${ compose } # define helper networks for helper_name in ${ !HELPER[@] } ; do echo -e \" ${ helper_name } :\" >> ${ compose } echo -e \" external:\" >> ${ compose } echo -e \" name: ${ helper_name } \" >> ${ compose } done } # remove trailing slash from ADM_HOME [[ \" ${ ADM_HOME } \" == */ ]] && ADM_HOME = \" ${ ADM_HOME : :- 1 } \" # create admin group, add members to group and set permissions groupadd -g ${ ADM_GID } ${ ADM_NAME } mkdir ${ ADM_HOME } chown -R root: ${ ADM_NAME } ${ ADM_HOME } chmod -R 775 ${ ADM_HOME } for user in ${ ADM_USERS } ; do adduser ${ user } ${ ADM_NAME } done # create helper networks for name in ${ !HELPER[@] } ; do subnet = ${ HELPER [ ${ name } ] } docker_network_create ${ name } ${ subnet } done # create stack logic mkdir -p ${ ADM_HOME } / { services,images,tools,docs } / for name in ${ !STACKS[@] } ; do subnet = ${ STACKS [ ${ name } ] } mkdir -p ${ ADM_HOME } / { services,images } / ${ name } / mkdir -p \"/srv/ ${ name } /\" # create stack network docker_network_create ${ name } ${ subnet } # create docker-compose.yml compose = \" ${ ADM_HOME } /services/ ${ name } /docker-compose.yml\" create_compose ${ compose } done","title":"Stack Logic"},{"location":"installation/stack-logic/#getting-started","text":"First, let's add the default directories into the admin directory: mkdir -p /home/admin/ { services,images,tools,docs } / name description services contains the docker-compose and .env files images contains the data for custom docker images tools contains various tools docs contains the documentations of you server For each stack we will create, we want to have a directory in /home/admin/services/ , /home/admin/images/ and /srv/ : The directory in /home/admin/services/ contains the docker-compose.yml and .env files. Which is later used in the docker-compose.yml as env_file . The directory in /home/admin/images/ contains the source files for the docker image if we have to build the image on the server. The directory in /srv/ is used to store persistent data for the stack (docker volumes). We will also create multiple docker networks, to give the containers the ability to communicate with each other. Helper networks for specific communication (e.g. to the reverse proxy, the databases or the monitoring) start at 192.168.0.0/24 . Stack networks (one network for each stack) start at 192.168.100.0/24 . Note that a network with the submask 255.255.255.0 (cidr notation is 24) can only contain 254 hosts. You have to adjust your network size to your needs. Remember the formular: \\(2^{32-x}-2\\) where \\(x\\) is your submask in cidr notation (e.g. with \\(24\\) : \\(2^{32\u221224}\u22122=254\\) ; or with \\(20\\) : \\(2^{32\u221220}\u22122=4094\\) usable adresses) Name Subnet Usage Proxy 192.168.0.0/24 Container communication to nginx reverse proxy. Database 192.168.1.0/24 Communication to databases (MariaDB, MongoDB, PostgreSQL). Monitoring 192.168.2.0/24 Communication to monitoring utilities (InfluxDB). Main 192.168.100.0/24 Network for the Main Stack # create main stack name = 'main' mkdir -p \"/home/admin/{services,images}/ ${ name } /\" sudo mkdir -p \"/srv/ ${ name } /\" sudo docker network create --subnet 192 .168.100.0/24 ${ name } # create helper networks (we will need them in the next chapter) sudo docker network create --subnet 192 .168.0.0/24 proxy sudo docker network create --subnet 192 .168.1.0/24 database sudo docker network create --subnet 192 .168.2.0/24 monitoring You can create as many stacks, as you need. The main stack contains the services that are relevant for the majority of the services (e.g. reverse proxy, static webserver for the reverse proxy, databases, admin panels (because they are related to the databases), monitoring). All other services will be outsourced to another stack. The following list containers just a few ideas, how you could name them: games: all game servers (e.g. Minecraft, Arma 3) storage: applications that store your data (e.g. NextCloud, Syncthing, ...) comms (short form of communication): things to communicate (e.g. TeamSpeak, Sinusbot, Telegram Bots, Discord Bots) jitsi: another video conference system (simply use their configuration on github ) Lastly we are going to create a docker-compose.yml which we will use to define our networks. version : \"3\" services : ... # you need to add your services right here... networks : default : external : name : main proxy : external : name : proxy database : external : name : database monitoring : external : name : monitoring The network created for a particular stack will be called default in the matching docker-compose.yml . This will help us, because if we do not specify a network in the service sections of the docker-compose.yml , these services will automatically connect network default . Parts of the PostInstall script covered in this chapter #!/bin/bash ## CONFIGURATION ### ADM_NAME = 'admin' ADM_GID = 997 ADM_HOME = '/home/admin' ADM_USERS =( 'user' ) declare -A STACKS =( \\ [ \"main\" ]= \"192.168.100.0/24\" ) declare -A HELPER =( \\ [ \"proxy\" ]= \"192.168.0.0/24\" \\ [ \"database\" ]= \"192.168.1.0/24\" \\ [ \"monitoring\" ]= \"192.168.2.0/24\" ) ### END of CONFIGURATION ### function docker_network_create () { name = ${ 1 } subnet = ${ 2 } docker network inspect ${ name } >/dev/null 2 > & 1 || \\ docker network create --subnet ${ subnet } ${ name } } function create_compose () { compose = ${ 1 } touch ${ compose } echo -e \"version: '3.8'\\n\" > ${ compose } # define services echo -e \"services:\\n\" >> ${ compose } if [[ ${# SERVICES } == 0 ]] ; then echo -e \" test:\" >> ${ compose } echo -e \" image: hello-world\\n\" >> ${ compose } fi echo -e \"\\n\" >> ${ compose } # define networks echo -e \"networks:\" >> ${ compose } # define stack network echo -e \" default:\" >> ${ compose } echo -e \" external:\" >> ${ compose } echo -e \" name: ${ name } \" >> ${ compose } # define helper networks for helper_name in ${ !HELPER[@] } ; do echo -e \" ${ helper_name } :\" >> ${ compose } echo -e \" external:\" >> ${ compose } echo -e \" name: ${ helper_name } \" >> ${ compose } done } # remove trailing slash from ADM_HOME [[ \" ${ ADM_HOME } \" == */ ]] && ADM_HOME = \" ${ ADM_HOME : :- 1 } \" # create admin group, add members to group and set permissions groupadd -g ${ ADM_GID } ${ ADM_NAME } mkdir ${ ADM_HOME } chown -R root: ${ ADM_NAME } ${ ADM_HOME } chmod -R 775 ${ ADM_HOME } for user in ${ ADM_USERS } ; do adduser ${ user } ${ ADM_NAME } done # create helper networks for name in ${ !HELPER[@] } ; do subnet = ${ HELPER [ ${ name } ] } docker_network_create ${ name } ${ subnet } done # create stack logic mkdir -p ${ ADM_HOME } / { services,images,tools,docs } / for name in ${ !STACKS[@] } ; do subnet = ${ STACKS [ ${ name } ] } mkdir -p ${ ADM_HOME } / { services,images } / ${ name } / mkdir -p \"/srv/ ${ name } /\" # create stack network docker_network_create ${ name } ${ subnet } # create docker-compose.yml compose = \" ${ ADM_HOME } /services/ ${ name } /docker-compose.yml\" create_compose ${ compose } done","title":"Getting Started"},{"location":"services/arma3/","text":"Linux Game Server Manager: Arma 3 Server \u00b6 Customize your image \u00b6 Create a custom entrypoint.sh , to start the arma 3 server automaticly: #!/bin/bash # start arma 3 server if already installed if [[ -e /home/linuxgsm/arma3server && -e /home/linuxgsm/serverfiles ]] ; then ~/arma3server start else # start the installation process cp /linuxgsm.sh ~/linuxgsm.sh echo 4 | ~/linuxgsm.sh install ~/arma3server install fi /usr/bin/tmux set -g status off && /usr/bin/tmux attach 2 > /dev/null tail -f /dev/null exit 0 Create a custom Dockerfile , which extends the lgsm image: FROM gameservermanagers/linuxgsm-docker USER root # install libtbb2:i386 for arma 3 extdb3 RUN dpkg --add-architecture i386 \\ && apt-get update -y \\ && apt-get upgrade -y \\ && apt-get install -y libtbb2:i386 \\ && rm -rf /var/lib/apt/lists/* # add custom entrypoint COPY entrypoint.sh /entrypoint.sh RUN chmod +x /entrypoint.sh USER linuxgsm Build your customized lgsm image: sudo docker build -t arma3server . Start the arma3 server \u00b6 Create your service definition in the docker-compose.yml of you games stack: arma3 : image : arma3server restart : always ports : - '2302:2302/udp' # Arma 3 + voice over network - '2303:2303/udp' # Steam Query - '2304:2304/udp' # Steam Master - '2305:2305/udp' # old Voice over Network - '2306:2306/udp' # BattleEye volumes : - '/srv/games/arma3:/home/lgsm' Start the service and execute a shell: sudo docker-compose up -d arma3 sudo docker-compose exec arma3 bash Add your steam account credentials to download the files of the gameserver. I suggest you create a new account for this: cat <<EOF >> ~/lgsm/config-lgsm/arma3server/arma3server.cfg steamuser=\"YOUR_USERNMAE\" steampass='YOUR_PASSWORD' EOF Afterwards you can start the installation process: ./arma3server install Importent configuration files \u00b6 # things that need to be done to start the server (e. g. mods) /srv/games/arma3/lgsm/config-lgsm/arma3server/arma3server.cfg # arma 3 server / network config /srv/games/arma3/serverfiles/cfg/arma3server.server.cfg /srv/games/arma3/serverfiles/cfg/arma3server.network.cfg","title":"Arma 3 Server"},{"location":"services/arma3/#linux-game-server-manager-arma-3-server","text":"","title":"Linux Game Server Manager: Arma 3 Server"},{"location":"services/arma3/#customize-your-image","text":"Create a custom entrypoint.sh , to start the arma 3 server automaticly: #!/bin/bash # start arma 3 server if already installed if [[ -e /home/linuxgsm/arma3server && -e /home/linuxgsm/serverfiles ]] ; then ~/arma3server start else # start the installation process cp /linuxgsm.sh ~/linuxgsm.sh echo 4 | ~/linuxgsm.sh install ~/arma3server install fi /usr/bin/tmux set -g status off && /usr/bin/tmux attach 2 > /dev/null tail -f /dev/null exit 0 Create a custom Dockerfile , which extends the lgsm image: FROM gameservermanagers/linuxgsm-docker USER root # install libtbb2:i386 for arma 3 extdb3 RUN dpkg --add-architecture i386 \\ && apt-get update -y \\ && apt-get upgrade -y \\ && apt-get install -y libtbb2:i386 \\ && rm -rf /var/lib/apt/lists/* # add custom entrypoint COPY entrypoint.sh /entrypoint.sh RUN chmod +x /entrypoint.sh USER linuxgsm Build your customized lgsm image: sudo docker build -t arma3server .","title":"Customize your image"},{"location":"services/arma3/#start-the-arma3-server","text":"Create your service definition in the docker-compose.yml of you games stack: arma3 : image : arma3server restart : always ports : - '2302:2302/udp' # Arma 3 + voice over network - '2303:2303/udp' # Steam Query - '2304:2304/udp' # Steam Master - '2305:2305/udp' # old Voice over Network - '2306:2306/udp' # BattleEye volumes : - '/srv/games/arma3:/home/lgsm' Start the service and execute a shell: sudo docker-compose up -d arma3 sudo docker-compose exec arma3 bash Add your steam account credentials to download the files of the gameserver. I suggest you create a new account for this: cat <<EOF >> ~/lgsm/config-lgsm/arma3server/arma3server.cfg steamuser=\"YOUR_USERNMAE\" steampass='YOUR_PASSWORD' EOF Afterwards you can start the installation process: ./arma3server install","title":"Start the arma3 server"},{"location":"services/arma3/#importent-configuration-files","text":"# things that need to be done to start the server (e. g. mods) /srv/games/arma3/lgsm/config-lgsm/arma3server/arma3server.cfg # arma 3 server / network config /srv/games/arma3/serverfiles/cfg/arma3server.server.cfg /srv/games/arma3/serverfiles/cfg/arma3server.network.cfg","title":"Importent configuration files"},{"location":"services/calibre/","text":"checkout linuxserver/calibre calibre : image : linuxserver/calibre-web restart : always environment : - \"PUID=1000\" - \"PGID=1000\" - \"SET_CONTAINER_TIMEZONE=true\" - \"CONTAINER_TIMEZONE=Europe/Berlin\" - \"USE_CONFIG_DIR=true\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_calibre.loadbalancer.server.port=8083\" - \"traefik.http.routers.r_calibre.rule=Host(`calibre.domain.de`)\" - \"traefik.http.routers.r_calibre.entrypoints=websecure\" - \"traefik.http.routers.r_calibre.tls.certresolver=myresolver\" volumes : - \"/srv/storage/calibre/config:/config\" - \"/srv/storage/calibre/books:/books\" networks : - proxy - database","title":"Calibre"},{"location":"services/docky-onion/","text":"Tor Hidden Services \u00b6 To provide tor hidden services through docker you can use docky-onion to make any of your services accessible through tor . Here is an example docker-compose.yml to serve an nginx as hidden service on port 80 and 8080 : version : \"3.9\" services : docky-onion : image : useto/docky-onion restart : always environment : # this forwards 80 and 8080 to web:80 - \"TOR_HIDDEN_SERVICE_WEB=80 web:80;8080 web:80\" volumes : - \"docky-onion:/var/lib/tor/hidden_services\" web : image : nginx restart : always depends_on : - docky-onion volumes : docky-onion : After you start the containers using docker-compose up -d docky-onion will proxy nginx into the tor network. Now we need to lookup the .onion -address using docker-compose exec docky-onion lookup . This will print something like the following: WEB => j3c7wmyv6b3q3uvowetwwygb7h57k2bjhtnwp2zfamda2ij2vanyhmid.onion Please note that you will get multiple .onion -address for each service you want to serve.","title":"docky-onion"},{"location":"services/docky-onion/#tor-hidden-services","text":"To provide tor hidden services through docker you can use docky-onion to make any of your services accessible through tor . Here is an example docker-compose.yml to serve an nginx as hidden service on port 80 and 8080 : version : \"3.9\" services : docky-onion : image : useto/docky-onion restart : always environment : # this forwards 80 and 8080 to web:80 - \"TOR_HIDDEN_SERVICE_WEB=80 web:80;8080 web:80\" volumes : - \"docky-onion:/var/lib/tor/hidden_services\" web : image : nginx restart : always depends_on : - docky-onion volumes : docky-onion : After you start the containers using docker-compose up -d docky-onion will proxy nginx into the tor network. Now we need to lookup the .onion -address using docker-compose exec docky-onion lookup . This will print something like the following: WEB => j3c7wmyv6b3q3uvowetwwygb7h57k2bjhtnwp2zfamda2ij2vanyhmid.onion Please note that you will get multiple .onion -address for each service you want to serve.","title":"Tor Hidden Services"},{"location":"services/element/","text":"Element WebClient \u00b6 The Element web client can be used by Matrix . element : image : vectorim/element-web restart : always volumes : - \"/srv/comms/element/data/config.json:/app/config.json\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_element.loadbalancer.server.port=80\" - \"traefik.http.routers.r_element.rule=Host(`element.domain.de`)\" - \"traefik.http.routers.r_element.entrypoints=websecure\" - \"traefik.http.routers.r_element.tls=true\" - \"traefik.http.routers.r_element.tls.certresolver=myresolver\" networks : - proxy Configuration \u00b6 First you need to create a config.json : mkdir -p /srv/comms/element/data/ touch /srv/comms/element/data/config.json Element supports a variety of settings to configure default servers, behaviour, themes, etc. Checkout the configuration docs for more details. Security note \u00b6 For security reasons, it is recommended that element is not used by the same domain as the Matrix homeserver. For more information see here","title":"Element"},{"location":"services/element/#element-webclient","text":"The Element web client can be used by Matrix . element : image : vectorim/element-web restart : always volumes : - \"/srv/comms/element/data/config.json:/app/config.json\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_element.loadbalancer.server.port=80\" - \"traefik.http.routers.r_element.rule=Host(`element.domain.de`)\" - \"traefik.http.routers.r_element.entrypoints=websecure\" - \"traefik.http.routers.r_element.tls=true\" - \"traefik.http.routers.r_element.tls.certresolver=myresolver\" networks : - proxy","title":"Element WebClient"},{"location":"services/element/#configuration","text":"First you need to create a config.json : mkdir -p /srv/comms/element/data/ touch /srv/comms/element/data/config.json Element supports a variety of settings to configure default servers, behaviour, themes, etc. Checkout the configuration docs for more details.","title":"Configuration"},{"location":"services/element/#security-note","text":"For security reasons, it is recommended that element is not used by the same domain as the Matrix homeserver. For more information see here","title":"Security note"},{"location":"services/gitea/","text":"Add the following to your docker-compose.yml Start the service ( docker-compose up -d ) Go to the configured domain to install gitea (e.g. configure db setup) gitea : image : gitea/gitea:latest restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_gitea.loadbalancer.server.port=3000\" - \"traefik.http.routers.r_gitea.rule=Host(`git.domain.de`)\" - \"traefik.http.routers.r_gitea.entrypoints=websecure\" - \"traefik.http.routers.r_gitea.tls=true\" - \"traefik.http.routers.r_gitea.tls.certresolver=myresolver\" volumes : - \"/srv/storage/gitea:/data\" - \"/etc/timezone:/etc/timezone:ro\" - \"/etc/localtime:/etc/localtime:ro\" ports : - \"22222:22\" networks : - default - proxy - database","title":"Gitea"},{"location":"services/hackmd/","text":"hackmd website hackmd on dockerhub hackmd : image : hackmdio/hackmd restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_hackmd.loadbalancer.server.port=3000\" - \"traefik.http.routers.r_hackmd.rule=Host(`md.domain.de`)\" - \"traefik.http.routers.r_hackmd.entrypoints=websecure\" - \"traefik.http.routers.r_hackmd.tls=true\" - \"traefik.http.routers.r_hackmd.tls.certresolver=myresolver\" environment : - CMD_DB_URL=mysql://hackmd:S3cr3T@mariadb/hackmd networks : - proxy - database","title":"HackMD"},{"location":"services/httpd-php/","text":"httpd with php \u00b6 php documentation homepage : image : php:apache2 restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=80\" - \"traefik.http.routers.r_homepage.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_homepage.entrypoints=websecure\" - \"traefik.http.routers.r_homepage.tls=true\" - \"traefik.http.routers.r_homepage.tls.certresolver=myresolver\" volumes : - \"/srv/main/homepage/webroot:/usr/share/nginx/html/\" networks : - proxy","title":"httpd with php"},{"location":"services/httpd-php/#httpd-with-php","text":"php documentation homepage : image : php:apache2 restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=80\" - \"traefik.http.routers.r_homepage.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_homepage.entrypoints=websecure\" - \"traefik.http.routers.r_homepage.tls=true\" - \"traefik.http.routers.r_homepage.tls.certresolver=myresolver\" volumes : - \"/srv/main/homepage/webroot:/usr/share/nginx/html/\" networks : - proxy","title":"httpd with php"},{"location":"services/httpd/","text":"httpd \u00b6 httpd documentation homepage : image : httpd:alpine restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=80\" - \"traefik.http.routers.r_homepage.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_homepage.entrypoints=websecure\" - \"traefik.http.routers.r_homepage.tls=true\" - \"traefik.http.routers.r_homepage.tls.certresolver=myresolver\" volumes : - \"/srv/main/homepage/webroot:/usr/share/nginx/html/\" networks : - proxy","title":"httpd"},{"location":"services/httpd/#httpd","text":"httpd documentation homepage : image : httpd:alpine restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=80\" - \"traefik.http.routers.r_homepage.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_homepage.entrypoints=websecure\" - \"traefik.http.routers.r_homepage.tls=true\" - \"traefik.http.routers.r_homepage.tls.certresolver=myresolver\" volumes : - \"/srv/main/homepage/webroot:/usr/share/nginx/html/\" networks : - proxy","title":"httpd"},{"location":"services/jitsi/","text":"Checkout the official guide I suggest you create a new stack for jitsi: # create directories mkdir -p /home/admin/ { services,images } /jitsi/ /srv/jitsi # create stack network docker network inspect ${ name } >/dev/null 2 > & 1 || \\ docker network create --subnet 192 .168.110.0/24 jitsi Afterwards you can download the required files from the jitsi/docker-jitsi-meet github repository wget https://raw.githubusercontent.com/jitsi/docker-jitsi-meet/master/docker-compose.yml -O /home/admin/services/jitsi/docker-compose.yml wget https://raw.githubusercontent.com/jitsi/docker-jitsi-meet/master/env.example -O /home/admin/services/jitsi/.env # generate new secrets cd /home/admin/services/jitsi/ curl https://raw.githubusercontent.com/jitsi/docker-jitsi-meet/master/gen-passwords.sh | bash # change configuration directory sed -i 's|CONFIG=.*|CONFIG=/srv/jitsi|g' .env Next step is to configure the .env file. Use Traefik \u00b6 Modify web services: remove port forwardings add traefik labels connect network: proxy After your changes the web service should look like this: web : image : jitsi/web:latest restart : ${RESTART_POLICY} # removed ports forwarding # added traefik labels labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_jitsi.loadbalancer.server.port=80\" - \"traefik.http.routers.r_jitsi.rule=Host(`jitsi.domain.de`)\" - \"traefik.http.routers.r_jitsi.entrypoints=websecure\" - \"traefik.http.routers.r_jitsi.tls.certresolver=myresolver\" volumes : - ${CONFIG}/web:/config:Z - ${CONFIG}/transcripts:/usr/share/jitsi-meet/transcripts:Z environment : - ENABLE_LETSENCRYPT - ... - TOKEN_AUTH_URL networks : # added proxy network proxy : meet.jitsi : aliases : - ${XMPP_DOMAIN} Use LDAP Auth Backend \u00b6 Modify prosody service: connect network: database configure ldap credentials After your changes the prosody service should look like this: # XMPP server prosody : image : jitsi/prosody:latest restart : ${RESTART_POLICY} expose : - '5222' - '5347' - '5280' volumes : - ${CONFIG}/prosody/config:/config:Z - ${CONFIG}/prosody/prosody-plugins-custom:/prosody-plugins-custom:Z environment : - AUTH_TYPE - ... - TZ networks : database : meet.jitsi : aliases : - ${XMPP_SERVER} The LDAP section of your .env should look like this (the not included keys are irrelevant if you don't use ldaps inside the docker network): # LDAP url for connection LDAP_URL = ldap://ldap # LDAP base DN. Can be empty LDAP_BASE = DC = domain,DC = com # LDAP user DN. Do not specify this parameter for the anonymous bind LDAP_BINDDN = CN = admin,DC = domain,DC = com # LDAP user password. Do not specify this parameter for the anonymous bind LDAP_BINDPW = S3cr3T # LDAP filter. Tokens example: # %1-9 - if the input key is user@mail.domain.com, then %1 is com, %2 is domain and %3 is mail # %s - %s is replaced by the complete service string # %r - %r is replaced by the complete realm string #LDAP_FILTER=(sAMAccountName=%u) # This filter only grants members of the jitsi group access LDAP_FILTER =( & ( objectclass = person )( & ( memberof = cn = jitsi,ou = groups,dc = domain,dc = de ))( uid = %u )) # ... Configuration \u00b6 All configurations are stored in the /srv/jitsi directory: You can't modify /srv/jitsi/web/config.js , because it will be regenerated on container start, but you can update the attributes in the .env file You can update the settings of your interface by modifying /srv/jitsi/web/interface_config.js Extend your Jitsi instance \u00b6 Etherpad \u00b6 Etherpad allows you to edit documents collaboratively in real-time. You can find the etherpad.yml in which the service is defined, in the github repo. I suggest you copy the etherpad service to your docker-compose.yml . Jibri \u00b6 The Jitsi Broadcasting Infrastructure provides services for recording or streaming. You can find the jibri.yml in which the service is defined, in the github repo. I suggest you copy the jibri service to your docker-compose.yml . Enable JVB Statictics (for monitoring) \u00b6 You can enable the colibri api of the jvb service by simply comment out JVB_ENABLE_APIS in the .env file. # A comma separated list of APIs to enable when the JVB is started [default: none] # See https://github.com/jitsi/jitsi-videobridge/blob/master/doc/rest.md for more information JVB_ENABLE_APIS = rest,colibri You can now request the statistics from the api: ip = $( docker inspect jitsi_jvb_1 | jq \".[0].NetworkSettings.Networks.jitsi.IPAddress\" | tr -d '\"' ) curl -s \"http:// ${ ip } :8080/colibri/stats\" | jq","title":"Jitsi"},{"location":"services/jitsi/#use-traefik","text":"Modify web services: remove port forwardings add traefik labels connect network: proxy After your changes the web service should look like this: web : image : jitsi/web:latest restart : ${RESTART_POLICY} # removed ports forwarding # added traefik labels labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_jitsi.loadbalancer.server.port=80\" - \"traefik.http.routers.r_jitsi.rule=Host(`jitsi.domain.de`)\" - \"traefik.http.routers.r_jitsi.entrypoints=websecure\" - \"traefik.http.routers.r_jitsi.tls.certresolver=myresolver\" volumes : - ${CONFIG}/web:/config:Z - ${CONFIG}/transcripts:/usr/share/jitsi-meet/transcripts:Z environment : - ENABLE_LETSENCRYPT - ... - TOKEN_AUTH_URL networks : # added proxy network proxy : meet.jitsi : aliases : - ${XMPP_DOMAIN}","title":"Use Traefik"},{"location":"services/jitsi/#use-ldap-auth-backend","text":"Modify prosody service: connect network: database configure ldap credentials After your changes the prosody service should look like this: # XMPP server prosody : image : jitsi/prosody:latest restart : ${RESTART_POLICY} expose : - '5222' - '5347' - '5280' volumes : - ${CONFIG}/prosody/config:/config:Z - ${CONFIG}/prosody/prosody-plugins-custom:/prosody-plugins-custom:Z environment : - AUTH_TYPE - ... - TZ networks : database : meet.jitsi : aliases : - ${XMPP_SERVER} The LDAP section of your .env should look like this (the not included keys are irrelevant if you don't use ldaps inside the docker network): # LDAP url for connection LDAP_URL = ldap://ldap # LDAP base DN. Can be empty LDAP_BASE = DC = domain,DC = com # LDAP user DN. Do not specify this parameter for the anonymous bind LDAP_BINDDN = CN = admin,DC = domain,DC = com # LDAP user password. Do not specify this parameter for the anonymous bind LDAP_BINDPW = S3cr3T # LDAP filter. Tokens example: # %1-9 - if the input key is user@mail.domain.com, then %1 is com, %2 is domain and %3 is mail # %s - %s is replaced by the complete service string # %r - %r is replaced by the complete realm string #LDAP_FILTER=(sAMAccountName=%u) # This filter only grants members of the jitsi group access LDAP_FILTER =( & ( objectclass = person )( & ( memberof = cn = jitsi,ou = groups,dc = domain,dc = de ))( uid = %u )) # ...","title":"Use LDAP Auth Backend"},{"location":"services/jitsi/#configuration","text":"All configurations are stored in the /srv/jitsi directory: You can't modify /srv/jitsi/web/config.js , because it will be regenerated on container start, but you can update the attributes in the .env file You can update the settings of your interface by modifying /srv/jitsi/web/interface_config.js","title":"Configuration"},{"location":"services/jitsi/#extend-your-jitsi-instance","text":"","title":"Extend your Jitsi instance"},{"location":"services/jitsi/#etherpad","text":"Etherpad allows you to edit documents collaboratively in real-time. You can find the etherpad.yml in which the service is defined, in the github repo. I suggest you copy the etherpad service to your docker-compose.yml .","title":"Etherpad"},{"location":"services/jitsi/#jibri","text":"The Jitsi Broadcasting Infrastructure provides services for recording or streaming. You can find the jibri.yml in which the service is defined, in the github repo. I suggest you copy the jibri service to your docker-compose.yml .","title":"Jibri"},{"location":"services/jitsi/#enable-jvb-statictics-for-monitoring","text":"You can enable the colibri api of the jvb service by simply comment out JVB_ENABLE_APIS in the .env file. # A comma separated list of APIs to enable when the JVB is started [default: none] # See https://github.com/jitsi/jitsi-videobridge/blob/master/doc/rest.md for more information JVB_ENABLE_APIS = rest,colibri You can now request the statistics from the api: ip = $( docker inspect jitsi_jvb_1 | jq \".[0].NetworkSettings.Networks.jitsi.IPAddress\" | tr -d '\"' ) curl -s \"http:// ${ ip } :8080/colibri/stats\" | jq","title":"Enable JVB Statictics (for monitoring)"},{"location":"services/mariadb/","text":"phpmyadmin documentation mariadb documentation You can generate a database and/or a user account which has full access on this database by setting the commented out environment variables. mariadb : image : mariadb restart : always environment : - \"MYSQL_ROOT_PASSWORD=S3cr3T\" #- \"MYSQL_DATABASE=app\" #- \"MYSQL_USER=app\" #- \"MYSQL_PASSWORD=S3cr3T\" volumes : - \"/srv/main/mariadb/data:/var/lib/mysql\" networks : - database phpmyadmin : image : phpmyadmin restart : \"no\" environment : - \"PMA_HOST=mariadb\" - \"PMA_PORT=3306\" - \"PMA_ABSOLUTE_URI=https://phpmyadmin.domain.tld/\" - \"UPLOAD_LIMIT=512M\" - \"HIDE_PHP_VERSION=true\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_phpmyadmin.loadbalancer.server.port=80\" - \"traefik.http.routers.r_phpmyadmin.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_phpmyadmin.entrypoints=websecure\" - \"traefik.http.routers.r_phpmyadmin.tls=true\" - \"traefik.http.routers.r_phpmyadmin.tls.certresolver=myresolver\" networks : - proxy - database","title":"MariaDB"},{"location":"services/matrix/","text":"First add this configuration to your docker-compose.yml matrix : image : matrixdotorg/synapse restart : always volumes : - /srv/comms/matrix/data:/data labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=8008\" - \"traefik.http.routers.r_matrix.rule=Host(`matrix.domain.de`)\" - \"traefik.http.routers.r_matrix.entrypoints=websecure\" - \"traefik.http.routers.r_matrix.tls=true\" - \"traefik.http.routers.r_matrix.tls.certresolver=myresolver\" networks : - proxy - database Before starting this container you need to generate a configuration file. This command generates a homeserver.yaml configuartion file under /srv/comms/matrix docker run -it --rm -v \"/srv/comms/matrix/data:/data\" -e \"SYNAPSE_SERVER_NAME=matrix.domain.de\" -e \"SYNAPSE_REPORT_STATS=no\" matrixdotorg/synapse:latest generate You have to specify the domain of the service using the SYNAPSE_SERVER_NAME environment variable. You also can enable anonymous statistics reporting by setting sthe SYNAPSE_REPORT_STATS to yes. After the command is done you can find the homeserver.yaml configurationfile in the data folder. Now you can start the service using docker-compose up -d matrix . Register a new user \u00b6 If you want to enable registration via Matrix clients such as element you can enable it in your homeserver.yaml file. ... enable_registration : true ... Don't forget to start the container after editing the option with docker-compose up -d You can also create a new user from the command line: docker-compose exec matrix register_new_matrix_user -u USERNAME -p PASSWORD -a -c /data/homeserver.yaml https://matrix.domain.de Using Postgres \u00b6 For using postgresql append this configuration to your docker-compose postgres : image : postgres restart : always environment : - \"POSTGRES_PASSWORD=S3cr3T\" - \"POSTGRES_DB=synapse\" - \"POSTGRES_INITDB_ARGS=-E UTF8 --lc-collate=C --lc-ctype=C\" volumes : - \"/srv/main/postgres/transfer:/transfer\" - \"/srv/main/postgres/data:/var/lib/postgresql/data\" networks : - database Now you have to edit the homeserver.yaml . Go to the Database section and uncomment it and add your postgresql settings. database : name : psycopg2 args : user : postgres password : secret database : synapse host : postgres cp_min : 5 cp_max : 10 By default, a SQLite database is used, so we still need to comment it out. #database: # name: sqlite3 # args: # database: /data/homeserver.db Now you are finish and you can start the container with docker-compose up -d Reset password of user \u00b6 If you want to reset the password run docker-compose exec -u www-data matrix hash_password -p PASSWORD After the command is done you will get a password hash as stdout. Once you have generated the password hash you can update the value in the database. First start a shell in the postgress container with. docker-compose exec postgres /bin/bash Next, you can update the password with the command PGPASSWORD = S3cr3T \\ psql -U postgres -d synapse -c \\ \"UPDATE users SET password_hash='\\$2a\\$12 $xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ' \\ WHERE name='@test:test.com';\" Federation \u00b6 To enable cross-server communication you need to set an SRV DNS record. ;; SRV Records _matrix._tcp.matrix.domain.de. 1 IN SRV 10 5 443 matrix.domain.de. Note You can also host your own Matrix WebClient. Host your own Matrix WebClient","title":"Matrix"},{"location":"services/matrix/#register-a-new-user","text":"If you want to enable registration via Matrix clients such as element you can enable it in your homeserver.yaml file. ... enable_registration : true ... Don't forget to start the container after editing the option with docker-compose up -d You can also create a new user from the command line: docker-compose exec matrix register_new_matrix_user -u USERNAME -p PASSWORD -a -c /data/homeserver.yaml https://matrix.domain.de","title":"Register a new user"},{"location":"services/matrix/#using-postgres","text":"For using postgresql append this configuration to your docker-compose postgres : image : postgres restart : always environment : - \"POSTGRES_PASSWORD=S3cr3T\" - \"POSTGRES_DB=synapse\" - \"POSTGRES_INITDB_ARGS=-E UTF8 --lc-collate=C --lc-ctype=C\" volumes : - \"/srv/main/postgres/transfer:/transfer\" - \"/srv/main/postgres/data:/var/lib/postgresql/data\" networks : - database Now you have to edit the homeserver.yaml . Go to the Database section and uncomment it and add your postgresql settings. database : name : psycopg2 args : user : postgres password : secret database : synapse host : postgres cp_min : 5 cp_max : 10 By default, a SQLite database is used, so we still need to comment it out. #database: # name: sqlite3 # args: # database: /data/homeserver.db Now you are finish and you can start the container with docker-compose up -d","title":"Using Postgres"},{"location":"services/matrix/#reset-password-of-user","text":"If you want to reset the password run docker-compose exec -u www-data matrix hash_password -p PASSWORD After the command is done you will get a password hash as stdout. Once you have generated the password hash you can update the value in the database. First start a shell in the postgress container with. docker-compose exec postgres /bin/bash Next, you can update the password with the command PGPASSWORD = S3cr3T \\ psql -U postgres -d synapse -c \\ \"UPDATE users SET password_hash='\\$2a\\$12 $xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ' \\ WHERE name='@test:test.com';\"","title":"Reset password of user"},{"location":"services/matrix/#federation","text":"To enable cross-server communication you need to set an SRV DNS record. ;; SRV Records _matrix._tcp.matrix.domain.de. 1 IN SRV 10 5 443 matrix.domain.de. Note You can also host your own Matrix WebClient. Host your own Matrix WebClient","title":"Federation"},{"location":"services/minecraft/","text":"Minecraft Server \u00b6 itzg/minecraft documentation minecraft : image : itzg/minecraft-server restart : always ports : - '25565:25565' volumes : - '/srv/games/minecraft:/data' environment : - 'TYPE=SPIGOT' - 'SPIGOT_DOWNLOAD_URL=https://cdn.getbukkit.org/spigot/spigot-1.16.3.jar' - 'OVERRIDE_SERVER_PROPERTIES=true' - 'EULA=TRUE' - 'MAX_PLAYERS=50' - 'TZ=Europe/Berlin' - 'MAX_MEMORY=8G' - 'MAX_RAM=8G' - 'MIN_RAM=4G' - 'ENABLE_AUTOPAUSE=TRUE' - 'MOTD=checkout https://felbinger.github.io/AdminGuide/' - 'SPAWN_PROTECTION=0' - 'SEED=2303273916051849791'","title":"Minecraft"},{"location":"services/minecraft/#minecraft-server","text":"itzg/minecraft documentation minecraft : image : itzg/minecraft-server restart : always ports : - '25565:25565' volumes : - '/srv/games/minecraft:/data' environment : - 'TYPE=SPIGOT' - 'SPIGOT_DOWNLOAD_URL=https://cdn.getbukkit.org/spigot/spigot-1.16.3.jar' - 'OVERRIDE_SERVER_PROPERTIES=true' - 'EULA=TRUE' - 'MAX_PLAYERS=50' - 'TZ=Europe/Berlin' - 'MAX_MEMORY=8G' - 'MAX_RAM=8G' - 'MIN_RAM=4G' - 'ENABLE_AUTOPAUSE=TRUE' - 'MOTD=checkout https://felbinger.github.io/AdminGuide/' - 'SPAWN_PROTECTION=0' - 'SEED=2303273916051849791'","title":"Minecraft Server"},{"location":"services/mongodb/","text":"mongodb documentation mongodb : image : mongo restart : always environment : - \"MONGO_INITDB_ROOT_USERNAME=root\" - \"MONGO_INITDB_ROOT_PASSWORD=S3cr3T\" volumes : - \"/etc/localtime:/etc/localtime:ro\" - \"/srv/main/mongodb/transfer:/data/transfer\" - \"/srv/main/mongodb/data:/data/db\" networks : - database","title":"MongoDB"},{"location":"services/monitoring/","text":"Resource Monitoring \u00b6 I'm using Telegraf , InfluxDB and Grafana as frontend to monitor my server resources. # shell: docker-compose exec influxdb influx -precision rfc3339 influxdb : image : influxdb restart : always #volumes: # - /srv/main/influxdb/lib:/var/lib/influxdb # - /srv/main/influxdb/influxdb.conf:/etc/influxdb/influxdb.conf environment : INFLUXDB_GRAPHITE_ENABLED : 1 networks : monitoring : ipv4_address : 192.168.2.254 grafana : image : grafana/grafana restart : always depends_on : - influxdb #volumes: # - /srv/main/grafana/lib:/var/lib/grafana # - /srv/main/grafana/etc:/etc/grafana # - /srv/main/grafana/log:/var/log/grafana environment : VIRTUAL_HOST : monitoring.domain.tld:3000 LETSENCRYPT_HOST : monitoring.domain.tld networks : - monitoring - proxy Unfortunately you need to copy the three volumes out of grafana before starting it up: mkdir -p /srv/main/ { grafana,influxdb } # copy data directory sudo docker cp main_grafana_1:/var/lib/grafana \\ /srv/main/grafana/lib # copy config directory sudo docker cp main_grafana_1:/etc/grafana \\ /srv/main/grafana/etc # copy log directory sudo docker cp main_grafana_1:/var/log/grafana \\ /srv/main/grafana/log # adjust permissions sudo chown -R 472 :472 /srv/main/grafana/ # influxdb sudo docker cp main_influxdb_1:/var/lib/influxdb \\ /srv/main/influxdb/lib sudo docker cp main_influxdb_1:/etc/influxdb/influxdb.conf \\ /srv/main/influxdb/influxdb.conf Afterwards you can remove the comments in front of the volumes and start up the container. The default login for grafana is admin : admin . Telegraf Collecting Agent \u00b6 $ sudo apt install apt-transport-https wget gnupg $ wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add - $ echo \"deb https://repos.influxdata.com/debian buster stable\" | sudo tee -a /etc/apt/sources.list.d/influxdb.list $ sudo apt update $ sudo apt install telegraf Command are below... In terms of configuration you first have to disable the influxdb output in the telegraf.conf . We are not going to use it, because it might be overwritten on telegraf updates. Just search for [[outputs.influxdb]] and put a # in front of it to mark it as a comment. The telegraf daemon will try to send data to the default url which is localhost:8086 . In our case, with influxdb inside the docker helper network, monitoring we will reach the influxdb on the ip address 192.168.2.254 via a network bridge (check ip route for more information). ... ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB #[[outputs.influxdb]] # <-- there ## The full HTTP or UDP URL for your InfluxDB instance. ## ## Multiple URLs can be specified for a single cluster, only ONE of the ## urls will be written to each interval. # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] # urls = [\"http://127.0.0.1:8086\"] ... Afterwards we are going to edit the copied telegraf configuration ( /etc/telegraf/telegraf.d/hostname.conf ). Just add the correct urls entry in the influxdb output area to get basic reporting which is enabled by default. ... ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB [[ outputs.influxdb ]] ## The full HTTP or UDP URL for your InfluxDB instance. ## ## Multiple URLs can be specified for a single cluster, only ONE of the ## urls will be written to each interval. # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] # urls = [\"http://127.0.0.1:8086\"] urls = [ \"http://192.168.2.254:8086\" ] # <-- there ... # configure telegraf (hostname.conf should match your hostname) sudo cp /etc/telegraf/telegraf. { conf,d/hostname.conf } sudo nano /etc/telegraf/telegraf. { conf,d/hostname.conf } sudo systemctl restart telegraf Monitoring docker instances from the host \u00b6 You can monitor your docker instances using the on the host running telegraf instance if you assign these docker containers a static ip address, like in influxdb: ... networks : database : ip_address : 192.168.1.254 ... Afterwards you can go to the input section in your telegraf configuration ( /etc/telegraf/telegraf.d/{hostname}.conf ) and add the new \"input's\". More Resources \u00b6 InfluxDB Authentication","title":"Monitoring"},{"location":"services/monitoring/#resource-monitoring","text":"I'm using Telegraf , InfluxDB and Grafana as frontend to monitor my server resources. # shell: docker-compose exec influxdb influx -precision rfc3339 influxdb : image : influxdb restart : always #volumes: # - /srv/main/influxdb/lib:/var/lib/influxdb # - /srv/main/influxdb/influxdb.conf:/etc/influxdb/influxdb.conf environment : INFLUXDB_GRAPHITE_ENABLED : 1 networks : monitoring : ipv4_address : 192.168.2.254 grafana : image : grafana/grafana restart : always depends_on : - influxdb #volumes: # - /srv/main/grafana/lib:/var/lib/grafana # - /srv/main/grafana/etc:/etc/grafana # - /srv/main/grafana/log:/var/log/grafana environment : VIRTUAL_HOST : monitoring.domain.tld:3000 LETSENCRYPT_HOST : monitoring.domain.tld networks : - monitoring - proxy Unfortunately you need to copy the three volumes out of grafana before starting it up: mkdir -p /srv/main/ { grafana,influxdb } # copy data directory sudo docker cp main_grafana_1:/var/lib/grafana \\ /srv/main/grafana/lib # copy config directory sudo docker cp main_grafana_1:/etc/grafana \\ /srv/main/grafana/etc # copy log directory sudo docker cp main_grafana_1:/var/log/grafana \\ /srv/main/grafana/log # adjust permissions sudo chown -R 472 :472 /srv/main/grafana/ # influxdb sudo docker cp main_influxdb_1:/var/lib/influxdb \\ /srv/main/influxdb/lib sudo docker cp main_influxdb_1:/etc/influxdb/influxdb.conf \\ /srv/main/influxdb/influxdb.conf Afterwards you can remove the comments in front of the volumes and start up the container. The default login for grafana is admin : admin .","title":"Resource Monitoring"},{"location":"services/monitoring/#telegraf-collecting-agent","text":"$ sudo apt install apt-transport-https wget gnupg $ wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add - $ echo \"deb https://repos.influxdata.com/debian buster stable\" | sudo tee -a /etc/apt/sources.list.d/influxdb.list $ sudo apt update $ sudo apt install telegraf Command are below... In terms of configuration you first have to disable the influxdb output in the telegraf.conf . We are not going to use it, because it might be overwritten on telegraf updates. Just search for [[outputs.influxdb]] and put a # in front of it to mark it as a comment. The telegraf daemon will try to send data to the default url which is localhost:8086 . In our case, with influxdb inside the docker helper network, monitoring we will reach the influxdb on the ip address 192.168.2.254 via a network bridge (check ip route for more information). ... ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB #[[outputs.influxdb]] # <-- there ## The full HTTP or UDP URL for your InfluxDB instance. ## ## Multiple URLs can be specified for a single cluster, only ONE of the ## urls will be written to each interval. # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] # urls = [\"http://127.0.0.1:8086\"] ... Afterwards we are going to edit the copied telegraf configuration ( /etc/telegraf/telegraf.d/hostname.conf ). Just add the correct urls entry in the influxdb output area to get basic reporting which is enabled by default. ... ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB [[ outputs.influxdb ]] ## The full HTTP or UDP URL for your InfluxDB instance. ## ## Multiple URLs can be specified for a single cluster, only ONE of the ## urls will be written to each interval. # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] # urls = [\"http://127.0.0.1:8086\"] urls = [ \"http://192.168.2.254:8086\" ] # <-- there ... # configure telegraf (hostname.conf should match your hostname) sudo cp /etc/telegraf/telegraf. { conf,d/hostname.conf } sudo nano /etc/telegraf/telegraf. { conf,d/hostname.conf } sudo systemctl restart telegraf","title":"Telegraf Collecting Agent"},{"location":"services/monitoring/#monitoring-docker-instances-from-the-host","text":"You can monitor your docker instances using the on the host running telegraf instance if you assign these docker containers a static ip address, like in influxdb: ... networks : database : ip_address : 192.168.1.254 ... Afterwards you can go to the input section in your telegraf configuration ( /etc/telegraf/telegraf.d/{hostname}.conf ) and add the new \"input's\".","title":"Monitoring docker instances from the host"},{"location":"services/monitoring/#more-resources","text":"InfluxDB Authentication","title":"More Resources"},{"location":"services/nginx-proxy/","text":"jwilder/nginx-proxy + letsencrypt \u00b6 A reverse proxy is a router which binds to the ports 80 (http) and 443 (https). You can access the configured services by connecting to the proxy ( https://domain.tld ) with a specific host header, which is going to be evaluated by the proxy. But how do you connect to your proxy with this specific host header? Due to the fact that you configured your dns to redirect all subdomains to your server you can simply access https://phpmyadmin.domain.tld . You will reach the reverse proxy on port 443 with the host header phpmyadmin.domain.tld , after evaluation the proxy will redirect the incomming request to the configured service. As far as I know, the development of the jwilder/nginx-proxy has been abandoned! Use Traefik instead! But one thing should be noted: This proxy is not able to bind two diffrent subdomains on two diffrent ports of the same container. So for example: a.domain.tld to port 80 and b.domain.tld to port 8080. But I found a solution for this issue: There is a nginx.tmpl with exactly this feature online available. Show Nginx Template (/srv/main/nginx/nginx.tmpl) {{ $CurrentContainer := where $ \"ID\" .Docker.CurrentContainerID | first }} {{ define \"upstream\" }} {{ if .Address }} {{/* If we got the containers from swarm and this container's port is published to host, use host IP:PORT */}} {{ if and .Container.Node.ID .Address.HostPort }} # {{ .Container.Node.Name }}/{{ .Container.Name }} server {{ .Container.Node.Address.IP }}:{{ .Address.HostPort }}; {{/* If there is no swarm node or the port is not published on host, use container's IP:PORT */}} {{ else if .Network }} # {{ .Container.Name }} server {{ .Network.IP }}:{{ .Address.Port }}; {{ end }} {{ else if .Network }} # {{ .Container.Name }} {{ if .Network.IP }} server {{ .Network.IP }} down; {{ else }} server 127.0.0.1 down; {{ end }} {{ end }} {{ end }} # If we receive X-Forwarded-Proto, pass it through; otherwise, pass along the # scheme used to connect to this server map $http_x_forwarded_proto $proxy_x_forwarded_proto { default $http_x_forwarded_proto; '' $scheme; } # If we receive X-Forwarded-Port, pass it through; otherwise, pass along the # server port the client connected to map $http_x_forwarded_port $proxy_x_forwarded_port { default $http_x_forwarded_port; '' $server_port; } # If we receive Upgrade, set Connection to \"upgrade\"; otherwise, delete any # Connection header that may have been passed to this server map $http_upgrade $proxy_connection { default upgrade; '' close; } # Apply fix for very long server names server_names_hash_bucket_size 128; # prevent server tokens from being shown (Custom modification) server_tokens off; # Default dhparam {{ if (exists \"/etc/nginx/dhparam/dhparam.pem\") }} ssl_dhparam /etc/nginx/dhparam/dhparam.pem; {{ end }} # Set appropriate X-Forwarded-Ssl header map $scheme $proxy_x_forwarded_ssl { default off; https on; } gzip_types text/plain text/css application/javascript application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; log_format vhost '$host $remote_addr - $remote_user [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; access_log off; {{ if $.Env.RESOLVERS }} resolver {{ $.Env.RESOLVERS }}; {{ end }} {{ if (exists \"/etc/nginx/proxy.conf\") }} include /etc/nginx/proxy.conf; {{ else }} # HTTP 1.1 support proxy_http_version 1.1; proxy_buffering off; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $proxy_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $proxy_x_forwarded_proto; proxy_set_header X-Forwarded-Ssl $proxy_x_forwarded_ssl; proxy_set_header X-Forwarded-Port $proxy_x_forwarded_port; # Mitigate httpoxy attack (see README for details) proxy_set_header Proxy \"\"; {{ end }} {{ $enable_ipv6 := eq (or ($.Env.ENABLE_IPV6) \"\") \"true\" }} server { server_name _; # This is just an invalid value which will never trigger on a real hostname. listen 80; {{ if $enable_ipv6 }} listen [::]:80; {{ end }} access_log /var/log/nginx/access.log vhost; return 503; } {{ if (and (exists \"/etc/nginx/certs/default.crt\") (exists \"/etc/nginx/certs/default.key\")) }} server { server_name _; # This is just an invalid value which will never trigger on a real hostname. listen 443 ssl http2; {{ if $enable_ipv6 }} listen [::]:443 ssl http2; {{ end }} access_log /var/log/nginx/access.log vhost; return 503; ssl_session_tickets off; ssl_certificate /etc/nginx/certs/default.crt; ssl_certificate_key /etc/nginx/certs/default.key; } {{ end }} {{ range $hostfull, $containers := groupByMulti $ \"Env.VIRTUAL_HOST\" \",\" }} {{ $host := first ( split $hostfull \":\" ) }} {{ $port := last ( split $hostfull \":\" ) }} {{ $is_regexp := hasPrefix \"~\" $host }} {{ $upstream_name := when $is_regexp (sha1 $host) $host }} # {{ $host }} upstream {{ $upstream_name }} { {{ range $container := $containers }} {{ $addrLen := len $container.Addresses }} {{ range $knownNetwork := $CurrentContainer.Networks }} {{ range $containerNetwork := $container.Networks }} {{ if (and (ne $containerNetwork.Name \"ingress\") (or (eq $knownNetwork.Name $containerNetwork.Name) (eq $knownNetwork.Name \"host\"))) }} ## Can be connected with \"{{ $containerNetwork.Name }}\" network {{/* If only 1 port exposed, use that */}} {{ if eq $addrLen 1 }} {{ $address := index $container.Addresses 0 }} {{ template \"upstream\" (dict \"Container\" $container \"Address\" $address \"Network\" $containerNetwork) }} {{/* If more than one port exposed, use the one after the colon in VIRTUAL_HOST env var, falling back to standard web port 80 */}} {{ else }} {{ $port := coalesce $port \"80\" }} {{ $address := where $container.Addresses \"Port\" $port | first }} {{ template \"upstream\" (dict \"Container\" $container \"Address\" $address \"Network\" $containerNetwork) }} {{ end }} {{ else }} # Cannot connect to network of this container server 127.0.0.1 down; {{ end }} {{ end }} {{ end }} {{ end }} } {{ $default_host := or ($.Env.DEFAULT_HOST) \"\" }} {{ $default_server := index (dict $host \"\" $default_host \"default_server\") $host }} {{/* Get the VIRTUAL_PROTO defined by containers w/ the same vhost, falling back to \"http\" */}} {{ $proto := trim (or (first (groupByKeys $containers \"Env.VIRTUAL_PROTO\")) \"http\") }} {{/* Get the NETWORK_ACCESS defined by containers w/ the same vhost, falling back to \"external\" */}} {{ $network_tag := or (first (groupByKeys $containers \"Env.NETWORK_ACCESS\")) \"external\" }} {{/* Get the HTTPS_METHOD defined by containers w/ the same vhost, falling back to \"redirect\" */}} {{ $https_method := or (first (groupByKeys $containers \"Env.HTTPS_METHOD\")) \"redirect\" }} {{/* Get the SSL_POLICY defined by containers w/ the same vhost, falling back to \"Mozilla-Intermediate\" */}} {{ $ssl_policy := or (first (groupByKeys $containers \"Env.SSL_POLICY\")) \"Mozilla-Intermediate\" }} {{/* Get the HSTS defined by containers w/ the same vhost, falling back to \"max-age=31536000\" */}} {{ $hsts := or (first (groupByKeys $containers \"Env.HSTS\")) \"max-age=31536000\" }} {{/* Get the VIRTUAL_ROOT By containers w/ use fastcgi root */}} {{ $vhost_root := or (first (groupByKeys $containers \"Env.VIRTUAL_ROOT\")) \"/var/www/public\" }} {{/* Get the first cert name defined by containers w/ the same vhost */}} {{ $certName := (first (groupByKeys $containers \"Env.CERT_NAME\")) }} {{/* Get the best matching cert by name for the vhost. */}} {{ $vhostCert := (closest (dir \"/etc/nginx/certs\") (printf \"%s.crt\" $host))}} {{/* vhostCert is actually a filename so remove any suffixes since they are added later */}} {{ $vhostCert := trimSuffix \".crt\" $vhostCert }} {{ $vhostCert := trimSuffix \".key\" $vhostCert }} {{/* Use the cert specified on the container or fallback to the best vhost match */}} {{ $cert := (coalesce $certName $vhostCert) }} {{ $is_https := (and (ne $https_method \"nohttps\") (ne $cert \"\") (exists (printf \"/etc/nginx/certs/%s.crt\" $cert)) (exists (printf \"/etc/nginx/certs/%s.key\" $cert))) }} {{ if $is_https }} {{ if eq $https_method \"redirect\" }} server { server_name {{ $host }}; listen 80 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:80 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; return 301 https://$host$request_uri; } {{ end }} server { server_name {{ $host }}; listen 443 ssl http2 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:443 ssl http2 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; {{ if eq $network_tag \"internal\" }} # Only allow traffic from internal clients include /etc/nginx/network_internal.conf; {{ end }} {{ if eq $ssl_policy \"Mozilla-Modern\" }} ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; {{ else if eq $ssl_policy \"Mozilla-Intermediate\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:!DSS'; {{ else if eq $ssl_policy \"Mozilla-Old\" }} ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:DES-CBC3-SHA:HIGH:SEED:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!RSAPSK:!aDH:!aECDH:!EDH-DSS-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!SRP'; {{ else if eq $ssl_policy \"AWS-TLS-1-2-2017-01\" }} ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:AES128-GCM-SHA256:AES128-SHA256:AES256-GCM-SHA384:AES256-SHA256'; {{ else if eq $ssl_policy \"AWS-TLS-1-1-2017-01\" }} ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA'; {{ else if eq $ssl_policy \"AWS-2016-08\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA'; {{ else if eq $ssl_policy \"AWS-2015-05\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DES-CBC3-SHA'; {{ else if eq $ssl_policy \"AWS-2015-03\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DHE-DSS-AES128-SHA:DES-CBC3-SHA'; {{ else if eq $ssl_policy \"AWS-2015-02\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DHE-DSS-AES128-SHA'; {{ end }} ssl_prefer_server_ciphers on; ssl_session_timeout 5m; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; ssl_certificate /etc/nginx/certs/{{ (printf \"%s.crt\" $cert) }}; ssl_certificate_key /etc/nginx/certs/{{ (printf \"%s.key\" $cert) }}; {{ if (exists (printf \"/etc/nginx/certs/%s.dhparam.pem\" $cert)) }} ssl_dhparam {{ printf \"/etc/nginx/certs/%s.dhparam.pem\" $cert }}; {{ end }} {{ if (exists (printf \"/etc/nginx/certs/%s.chain.pem\" $cert)) }} ssl_stapling on; ssl_stapling_verify on; ssl_trusted_certificate {{ printf \"/etc/nginx/certs/%s.chain.pem\" $cert }}; {{ end }} {{ if (not (or (eq $https_method \"noredirect\") (eq $hsts \"off\"))) }} add_header Strict-Transport-Security \"{{ trim $hsts }}\" always; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s\" $host }}; {{ else if (exists \"/etc/nginx/vhost.d/default\") }} include /etc/nginx/vhost.d/default; {{ end }} client_max_body_size 2000m; location / { {{ if eq $proto \"uwsgi\" }} include uwsgi_params; uwsgi_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ else if eq $proto \"fastcgi\" }} root {{ trim $vhost_root }}; include fastcgi.conf; fastcgi_pass {{ trim $upstream_name }}; {{ else }} proxy_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ end }} {{ if (exists (printf \"/etc/nginx/htpasswd/%s\" $host)) }} auth_basic \"Restricted {{ $host }}\"; auth_basic_user_file {{ (printf \"/etc/nginx/htpasswd/%s\" $host) }}; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s_location\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s_location\" $host}}; {{ else if (exists \"/etc/nginx/vhost.d/default_location\") }} include /etc/nginx/vhost.d/default_location; {{ end }} {{ if (exists (printf \"/etc/nginx/acl/%s\" $host)) }} # IP based Access Control -> checkout https://github.com/felbinger/acl include {{ printf \"/etc/nginx/acl/%s\" $host}}; {{ end }} client_max_body_size 2000m; } } {{ end }} {{ if or (not $is_https) (eq $https_method \"noredirect\") }} server { server_name {{ $host }}; listen 80 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:80 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; {{ if eq $network_tag \"internal\" }} # Only allow traffic from internal clients include /etc/nginx/network_internal.conf; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s\" $host }}; {{ else if (exists \"/etc/nginx/vhost.d/default\") }} include /etc/nginx/vhost.d/default; {{ end }} location / { {{ if eq $proto \"uwsgi\" }} include uwsgi_params; uwsgi_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ else if eq $proto \"fastcgi\" }} root {{ trim $vhost_root }}; include fastcgi.conf; fastcgi_pass {{ trim $upstream_name }}; {{ else }} proxy_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ end }} {{ if (exists (printf \"/etc/nginx/htpasswd/%s\" $host)) }} auth_basic \"Restricted {{ $host }}\"; auth_basic_user_file {{ (printf \"/etc/nginx/htpasswd/%s\" $host) }}; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s_location\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s_location\" $host}}; {{ else if (exists \"/etc/nginx/vhost.d/default_location\") }} include /etc/nginx/vhost.d/default_location; {{ end }} {{ if (exists (printf \"/etc/nginx/acl/%s\" $host)) }} # IP based Access Control -> checkout https://github.com/felbinger/acl include {{ printf \"/etc/nginx/acl/%s\" $host}}; {{ end }} } } {{ if (and (not $is_https) (exists \"/etc/nginx/certs/default.crt\") (exists \"/etc/nginx/certs/default.key\")) }} server { server_name {{ $host }}; listen 443 ssl http2 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:443 ssl http2 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; return 500; ssl_certificate /etc/nginx/certs/default.crt; ssl_certificate_key /etc/nginx/certs/default.key; } {{ end }} {{ end }} {{ end }} nginx : image : jwilder/nginx-proxy restart : always ports : - '80:80' - '443:443' volumes : - 'nginx-certs:/etc/nginx/certs' - 'nginx-vhosts:/etc/nginx/vhost.d' - '/srv/main/nginx/conf.d:/etc/nginx/conf.d' - '/srv/main/nginx/acl:/etc/nginx/acl' - '/srv/main/nginx/webroot:/usr/share/nginx/html' - '/srv/main/nginx/nginx.tmpl:/app/nginx.tmpl' - '/var/run/docker.sock:/tmp/docker.sock:ro' labels : - com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy environment : DEFAULT_HOST : domain.tld networks : - proxy letsencrypt : image : jrcs/letsencrypt-nginx-proxy-companion restart : always environment : NGINX_PROXY_CONTAINER : main_nginx_1 DEFAULT_EMAIL : monitoring@domain.tld volumes : - 'nginx-certs:/etc/nginx/certs' - 'nginx-vhosts:/etc/nginx/vhost.d' - '/srv/main/nginx/conf.d:/etc/nginx/conf.d' - '/srv/main/nginx/webroot:/usr/share/nginx/html' - '/var/run/docker.sock:/var/run/docker.sock:ro' networks : - proxy We also need to specify the three used volumes at the end of the docker-compose.yml volumes : nginx-certs : nginx-vhosts :","title":"nginx/proxy"},{"location":"services/nginx-proxy/#jwildernginx-proxy-letsencrypt","text":"A reverse proxy is a router which binds to the ports 80 (http) and 443 (https). You can access the configured services by connecting to the proxy ( https://domain.tld ) with a specific host header, which is going to be evaluated by the proxy. But how do you connect to your proxy with this specific host header? Due to the fact that you configured your dns to redirect all subdomains to your server you can simply access https://phpmyadmin.domain.tld . You will reach the reverse proxy on port 443 with the host header phpmyadmin.domain.tld , after evaluation the proxy will redirect the incomming request to the configured service. As far as I know, the development of the jwilder/nginx-proxy has been abandoned! Use Traefik instead! But one thing should be noted: This proxy is not able to bind two diffrent subdomains on two diffrent ports of the same container. So for example: a.domain.tld to port 80 and b.domain.tld to port 8080. But I found a solution for this issue: There is a nginx.tmpl with exactly this feature online available. Show Nginx Template (/srv/main/nginx/nginx.tmpl) {{ $CurrentContainer := where $ \"ID\" .Docker.CurrentContainerID | first }} {{ define \"upstream\" }} {{ if .Address }} {{/* If we got the containers from swarm and this container's port is published to host, use host IP:PORT */}} {{ if and .Container.Node.ID .Address.HostPort }} # {{ .Container.Node.Name }}/{{ .Container.Name }} server {{ .Container.Node.Address.IP }}:{{ .Address.HostPort }}; {{/* If there is no swarm node or the port is not published on host, use container's IP:PORT */}} {{ else if .Network }} # {{ .Container.Name }} server {{ .Network.IP }}:{{ .Address.Port }}; {{ end }} {{ else if .Network }} # {{ .Container.Name }} {{ if .Network.IP }} server {{ .Network.IP }} down; {{ else }} server 127.0.0.1 down; {{ end }} {{ end }} {{ end }} # If we receive X-Forwarded-Proto, pass it through; otherwise, pass along the # scheme used to connect to this server map $http_x_forwarded_proto $proxy_x_forwarded_proto { default $http_x_forwarded_proto; '' $scheme; } # If we receive X-Forwarded-Port, pass it through; otherwise, pass along the # server port the client connected to map $http_x_forwarded_port $proxy_x_forwarded_port { default $http_x_forwarded_port; '' $server_port; } # If we receive Upgrade, set Connection to \"upgrade\"; otherwise, delete any # Connection header that may have been passed to this server map $http_upgrade $proxy_connection { default upgrade; '' close; } # Apply fix for very long server names server_names_hash_bucket_size 128; # prevent server tokens from being shown (Custom modification) server_tokens off; # Default dhparam {{ if (exists \"/etc/nginx/dhparam/dhparam.pem\") }} ssl_dhparam /etc/nginx/dhparam/dhparam.pem; {{ end }} # Set appropriate X-Forwarded-Ssl header map $scheme $proxy_x_forwarded_ssl { default off; https on; } gzip_types text/plain text/css application/javascript application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; log_format vhost '$host $remote_addr - $remote_user [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; access_log off; {{ if $.Env.RESOLVERS }} resolver {{ $.Env.RESOLVERS }}; {{ end }} {{ if (exists \"/etc/nginx/proxy.conf\") }} include /etc/nginx/proxy.conf; {{ else }} # HTTP 1.1 support proxy_http_version 1.1; proxy_buffering off; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $proxy_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $proxy_x_forwarded_proto; proxy_set_header X-Forwarded-Ssl $proxy_x_forwarded_ssl; proxy_set_header X-Forwarded-Port $proxy_x_forwarded_port; # Mitigate httpoxy attack (see README for details) proxy_set_header Proxy \"\"; {{ end }} {{ $enable_ipv6 := eq (or ($.Env.ENABLE_IPV6) \"\") \"true\" }} server { server_name _; # This is just an invalid value which will never trigger on a real hostname. listen 80; {{ if $enable_ipv6 }} listen [::]:80; {{ end }} access_log /var/log/nginx/access.log vhost; return 503; } {{ if (and (exists \"/etc/nginx/certs/default.crt\") (exists \"/etc/nginx/certs/default.key\")) }} server { server_name _; # This is just an invalid value which will never trigger on a real hostname. listen 443 ssl http2; {{ if $enable_ipv6 }} listen [::]:443 ssl http2; {{ end }} access_log /var/log/nginx/access.log vhost; return 503; ssl_session_tickets off; ssl_certificate /etc/nginx/certs/default.crt; ssl_certificate_key /etc/nginx/certs/default.key; } {{ end }} {{ range $hostfull, $containers := groupByMulti $ \"Env.VIRTUAL_HOST\" \",\" }} {{ $host := first ( split $hostfull \":\" ) }} {{ $port := last ( split $hostfull \":\" ) }} {{ $is_regexp := hasPrefix \"~\" $host }} {{ $upstream_name := when $is_regexp (sha1 $host) $host }} # {{ $host }} upstream {{ $upstream_name }} { {{ range $container := $containers }} {{ $addrLen := len $container.Addresses }} {{ range $knownNetwork := $CurrentContainer.Networks }} {{ range $containerNetwork := $container.Networks }} {{ if (and (ne $containerNetwork.Name \"ingress\") (or (eq $knownNetwork.Name $containerNetwork.Name) (eq $knownNetwork.Name \"host\"))) }} ## Can be connected with \"{{ $containerNetwork.Name }}\" network {{/* If only 1 port exposed, use that */}} {{ if eq $addrLen 1 }} {{ $address := index $container.Addresses 0 }} {{ template \"upstream\" (dict \"Container\" $container \"Address\" $address \"Network\" $containerNetwork) }} {{/* If more than one port exposed, use the one after the colon in VIRTUAL_HOST env var, falling back to standard web port 80 */}} {{ else }} {{ $port := coalesce $port \"80\" }} {{ $address := where $container.Addresses \"Port\" $port | first }} {{ template \"upstream\" (dict \"Container\" $container \"Address\" $address \"Network\" $containerNetwork) }} {{ end }} {{ else }} # Cannot connect to network of this container server 127.0.0.1 down; {{ end }} {{ end }} {{ end }} {{ end }} } {{ $default_host := or ($.Env.DEFAULT_HOST) \"\" }} {{ $default_server := index (dict $host \"\" $default_host \"default_server\") $host }} {{/* Get the VIRTUAL_PROTO defined by containers w/ the same vhost, falling back to \"http\" */}} {{ $proto := trim (or (first (groupByKeys $containers \"Env.VIRTUAL_PROTO\")) \"http\") }} {{/* Get the NETWORK_ACCESS defined by containers w/ the same vhost, falling back to \"external\" */}} {{ $network_tag := or (first (groupByKeys $containers \"Env.NETWORK_ACCESS\")) \"external\" }} {{/* Get the HTTPS_METHOD defined by containers w/ the same vhost, falling back to \"redirect\" */}} {{ $https_method := or (first (groupByKeys $containers \"Env.HTTPS_METHOD\")) \"redirect\" }} {{/* Get the SSL_POLICY defined by containers w/ the same vhost, falling back to \"Mozilla-Intermediate\" */}} {{ $ssl_policy := or (first (groupByKeys $containers \"Env.SSL_POLICY\")) \"Mozilla-Intermediate\" }} {{/* Get the HSTS defined by containers w/ the same vhost, falling back to \"max-age=31536000\" */}} {{ $hsts := or (first (groupByKeys $containers \"Env.HSTS\")) \"max-age=31536000\" }} {{/* Get the VIRTUAL_ROOT By containers w/ use fastcgi root */}} {{ $vhost_root := or (first (groupByKeys $containers \"Env.VIRTUAL_ROOT\")) \"/var/www/public\" }} {{/* Get the first cert name defined by containers w/ the same vhost */}} {{ $certName := (first (groupByKeys $containers \"Env.CERT_NAME\")) }} {{/* Get the best matching cert by name for the vhost. */}} {{ $vhostCert := (closest (dir \"/etc/nginx/certs\") (printf \"%s.crt\" $host))}} {{/* vhostCert is actually a filename so remove any suffixes since they are added later */}} {{ $vhostCert := trimSuffix \".crt\" $vhostCert }} {{ $vhostCert := trimSuffix \".key\" $vhostCert }} {{/* Use the cert specified on the container or fallback to the best vhost match */}} {{ $cert := (coalesce $certName $vhostCert) }} {{ $is_https := (and (ne $https_method \"nohttps\") (ne $cert \"\") (exists (printf \"/etc/nginx/certs/%s.crt\" $cert)) (exists (printf \"/etc/nginx/certs/%s.key\" $cert))) }} {{ if $is_https }} {{ if eq $https_method \"redirect\" }} server { server_name {{ $host }}; listen 80 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:80 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; return 301 https://$host$request_uri; } {{ end }} server { server_name {{ $host }}; listen 443 ssl http2 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:443 ssl http2 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; {{ if eq $network_tag \"internal\" }} # Only allow traffic from internal clients include /etc/nginx/network_internal.conf; {{ end }} {{ if eq $ssl_policy \"Mozilla-Modern\" }} ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; {{ else if eq $ssl_policy \"Mozilla-Intermediate\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:!DSS'; {{ else if eq $ssl_policy \"Mozilla-Old\" }} ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:DES-CBC3-SHA:HIGH:SEED:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!RSAPSK:!aDH:!aECDH:!EDH-DSS-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!SRP'; {{ else if eq $ssl_policy \"AWS-TLS-1-2-2017-01\" }} ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:AES128-GCM-SHA256:AES128-SHA256:AES256-GCM-SHA384:AES256-SHA256'; {{ else if eq $ssl_policy \"AWS-TLS-1-1-2017-01\" }} ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA'; {{ else if eq $ssl_policy \"AWS-2016-08\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA'; {{ else if eq $ssl_policy \"AWS-2015-05\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DES-CBC3-SHA'; {{ else if eq $ssl_policy \"AWS-2015-03\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DHE-DSS-AES128-SHA:DES-CBC3-SHA'; {{ else if eq $ssl_policy \"AWS-2015-02\" }} ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DHE-DSS-AES128-SHA'; {{ end }} ssl_prefer_server_ciphers on; ssl_session_timeout 5m; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; ssl_certificate /etc/nginx/certs/{{ (printf \"%s.crt\" $cert) }}; ssl_certificate_key /etc/nginx/certs/{{ (printf \"%s.key\" $cert) }}; {{ if (exists (printf \"/etc/nginx/certs/%s.dhparam.pem\" $cert)) }} ssl_dhparam {{ printf \"/etc/nginx/certs/%s.dhparam.pem\" $cert }}; {{ end }} {{ if (exists (printf \"/etc/nginx/certs/%s.chain.pem\" $cert)) }} ssl_stapling on; ssl_stapling_verify on; ssl_trusted_certificate {{ printf \"/etc/nginx/certs/%s.chain.pem\" $cert }}; {{ end }} {{ if (not (or (eq $https_method \"noredirect\") (eq $hsts \"off\"))) }} add_header Strict-Transport-Security \"{{ trim $hsts }}\" always; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s\" $host }}; {{ else if (exists \"/etc/nginx/vhost.d/default\") }} include /etc/nginx/vhost.d/default; {{ end }} client_max_body_size 2000m; location / { {{ if eq $proto \"uwsgi\" }} include uwsgi_params; uwsgi_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ else if eq $proto \"fastcgi\" }} root {{ trim $vhost_root }}; include fastcgi.conf; fastcgi_pass {{ trim $upstream_name }}; {{ else }} proxy_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ end }} {{ if (exists (printf \"/etc/nginx/htpasswd/%s\" $host)) }} auth_basic \"Restricted {{ $host }}\"; auth_basic_user_file {{ (printf \"/etc/nginx/htpasswd/%s\" $host) }}; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s_location\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s_location\" $host}}; {{ else if (exists \"/etc/nginx/vhost.d/default_location\") }} include /etc/nginx/vhost.d/default_location; {{ end }} {{ if (exists (printf \"/etc/nginx/acl/%s\" $host)) }} # IP based Access Control -> checkout https://github.com/felbinger/acl include {{ printf \"/etc/nginx/acl/%s\" $host}}; {{ end }} client_max_body_size 2000m; } } {{ end }} {{ if or (not $is_https) (eq $https_method \"noredirect\") }} server { server_name {{ $host }}; listen 80 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:80 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; {{ if eq $network_tag \"internal\" }} # Only allow traffic from internal clients include /etc/nginx/network_internal.conf; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s\" $host }}; {{ else if (exists \"/etc/nginx/vhost.d/default\") }} include /etc/nginx/vhost.d/default; {{ end }} location / { {{ if eq $proto \"uwsgi\" }} include uwsgi_params; uwsgi_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ else if eq $proto \"fastcgi\" }} root {{ trim $vhost_root }}; include fastcgi.conf; fastcgi_pass {{ trim $upstream_name }}; {{ else }} proxy_pass {{ trim $proto }}://{{ trim $upstream_name }}; {{ end }} {{ if (exists (printf \"/etc/nginx/htpasswd/%s\" $host)) }} auth_basic \"Restricted {{ $host }}\"; auth_basic_user_file {{ (printf \"/etc/nginx/htpasswd/%s\" $host) }}; {{ end }} {{ if (exists (printf \"/etc/nginx/vhost.d/%s_location\" $host)) }} include {{ printf \"/etc/nginx/vhost.d/%s_location\" $host}}; {{ else if (exists \"/etc/nginx/vhost.d/default_location\") }} include /etc/nginx/vhost.d/default_location; {{ end }} {{ if (exists (printf \"/etc/nginx/acl/%s\" $host)) }} # IP based Access Control -> checkout https://github.com/felbinger/acl include {{ printf \"/etc/nginx/acl/%s\" $host}}; {{ end }} } } {{ if (and (not $is_https) (exists \"/etc/nginx/certs/default.crt\") (exists \"/etc/nginx/certs/default.key\")) }} server { server_name {{ $host }}; listen 443 ssl http2 {{ $default_server }}; {{ if $enable_ipv6 }} listen [::]:443 ssl http2 {{ $default_server }}; {{ end }} access_log /var/log/nginx/access.log vhost; return 500; ssl_certificate /etc/nginx/certs/default.crt; ssl_certificate_key /etc/nginx/certs/default.key; } {{ end }} {{ end }} {{ end }} nginx : image : jwilder/nginx-proxy restart : always ports : - '80:80' - '443:443' volumes : - 'nginx-certs:/etc/nginx/certs' - 'nginx-vhosts:/etc/nginx/vhost.d' - '/srv/main/nginx/conf.d:/etc/nginx/conf.d' - '/srv/main/nginx/acl:/etc/nginx/acl' - '/srv/main/nginx/webroot:/usr/share/nginx/html' - '/srv/main/nginx/nginx.tmpl:/app/nginx.tmpl' - '/var/run/docker.sock:/tmp/docker.sock:ro' labels : - com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy environment : DEFAULT_HOST : domain.tld networks : - proxy letsencrypt : image : jrcs/letsencrypt-nginx-proxy-companion restart : always environment : NGINX_PROXY_CONTAINER : main_nginx_1 DEFAULT_EMAIL : monitoring@domain.tld volumes : - 'nginx-certs:/etc/nginx/certs' - 'nginx-vhosts:/etc/nginx/vhost.d' - '/srv/main/nginx/conf.d:/etc/nginx/conf.d' - '/srv/main/nginx/webroot:/usr/share/nginx/html' - '/var/run/docker.sock:/var/run/docker.sock:ro' networks : - proxy We also need to specify the three used volumes at the end of the docker-compose.yml volumes : nginx-certs : nginx-vhosts :","title":"jwilder/nginx-proxy + letsencrypt"},{"location":"services/nginx/","text":"nginx documentation homepage : image : nginx restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_homepage.loadbalancer.server.port=80\" - \"traefik.http.routers.r_homepage.rule=Host(`phpmyadmin.domain.de`)\" - \"traefik.http.routers.r_homepage.entrypoints=websecure\" - \"traefik.http.routers.r_homepage.tls=true\" - \"traefik.http.routers.r_homepage.tls.certresolver=myresolver\" volumes : - \"/srv/main/homepage/webroot:/usr/share/nginx/html/\" networks : - proxy","title":"nginx"},{"location":"services/openldap/","text":"I tested a lot of prebuild docker images and I came to the conclusion that the one from osixia/openldap:1.4.0 works best. Unfortunately neither the bcrypt hashing algorithm nor the PBKDF2 hashing algorithm is being support. So, we are going to use osixia's image as base, and add the bcrypt hashing algorithm (checkout howardlau1999/openldap-bcrypt-docker ). I like to combine every service with a administrative webinterface. I use phpldapadmin which is also available from osixia: osixia/docker-phpLDAPadmin . Today's version of phpldapadmin from osixia is 1.2.5, but there is version 1.2.6.2 (which supports bcrypt), so let's clone also this git repository to build the image with the correct version of phpldapadmin. A friend of mine, who's also supporting me with the admin guide, has build a custom phpldapadmin image, which only supports secure hashing algorithms and is based on a small alpine image. Checkout his git repository or simply use his docker image: marcelcoding/phpldapadmin ldap : image : howardlau1999/openldap-bcrypt restart : always environment : - \"LDAP_ORGANISATION=Company Name\" - \"LDAP_DOMAIN=domain.de\" - \"LDAP_ADMIN_PASSWORD=S3cr3T\" volumes : - \"/srv/main/ldap/data:/var/lib/ldap\" - \"/srv/main/ldap/config:/etc/ldap/slapd.d\" networks : - database ldapadmin : image : marcelcoding/phpldapadmin restart : always environment : - 'LDAP_HOST=ldap' - 'LDAP_BIND_DN=cn=admin,dc=domain,dc=de' labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_ldapadmin.loadbalancer.server.port=80\" - \"traefik.http.routers.r_ldapadmin.rule=Host(`ldapadmin.domain.de`)\" - \"traefik.http.routers.r_ldapadmin.entrypoints=websecure\" - \"traefik.http.routers.r_ldapadmin.tls.certresolver=myresolver\" networks : - database - proxy Custom Schemas \u00b6 SSH Public Key Schema \u00b6 Create the openssh-lpk.ldif file (I tried to refactor this multiple times, just leave it as it is...) # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 f6bf57a2 dn: cn=openssh-lpk,cn=schema,cn=config objectClass: olcSchemaConfig cn: openssh-lpk olcAttributeTypes: {0}( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey' DES C 'MANDATORY: OpenSSH Public key' EQUALITY octetStringMatch SYNTAX 1.3.6.1.4. 1.1466.115.121.1.40 ) olcObjectClasses: {0}( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' DESC 'MANDATORY: OpenSSH LPK objectclass' SUP top AUXILIARY MAY ( sshPublicKey $ uid ) ) Add the schema to your ldap server: $ ldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 LDAP Command Line Basics \u00b6 Checkout the official OpenLDAP Admin Guide # query your ldap ldapsearch -x -D 'cn=admin,dc=domain,dc=de' -w 'admin' -b 'dc=domain,dc=de' # add entries to your ldap # 1. create ldif file which contains the entry # 2. import it using ldapadd ldapadd -x -D 'cn=admin,dc=domain,dc=de' -w 'admin' -f your_entry.ldif","title":"OpenLDAP"},{"location":"services/openldap/#custom-schemas","text":"","title":"Custom Schemas"},{"location":"services/openldap/#ssh-public-key-schema","text":"Create the openssh-lpk.ldif file (I tried to refactor this multiple times, just leave it as it is...) # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 f6bf57a2 dn: cn=openssh-lpk,cn=schema,cn=config objectClass: olcSchemaConfig cn: openssh-lpk olcAttributeTypes: {0}( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey' DES C 'MANDATORY: OpenSSH Public key' EQUALITY octetStringMatch SYNTAX 1.3.6.1.4. 1.1466.115.121.1.40 ) olcObjectClasses: {0}( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' DESC 'MANDATORY: OpenSSH LPK objectclass' SUP top AUXILIARY MAY ( sshPublicKey $ uid ) ) Add the schema to your ldap server: $ ldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0","title":"SSH Public Key Schema"},{"location":"services/openldap/#ldap-command-line-basics","text":"Checkout the official OpenLDAP Admin Guide # query your ldap ldapsearch -x -D 'cn=admin,dc=domain,dc=de' -w 'admin' -b 'dc=domain,dc=de' # add entries to your ldap # 1. create ldif file which contains the entry # 2. import it using ldapadd ldapadd -x -D 'cn=admin,dc=domain,dc=de' -w 'admin' -f your_entry.ldif","title":"LDAP Command Line Basics"},{"location":"services/postgresql/","text":"PostgreSQL \u00b6 postgres documentation You can generate a database by setting the commented out environment variables. postgresql : image : postgres restart : always environment : - \"POSTGRES_PASSWORD=S3cr3T\" #- \"POSTGRES_DB=app\" volumes : - \"/srv/main/postgres/transfer:/transfer\" - \"/srv/main/postgres/data:/var/lib/postgresql/data\" networks : - database pgAdmin 4 \u00b6 pgadmin : image : dpage/pgadmin4 restart : always environment : - \"PGADMIN_DEFAULT_EMAIL=admin@domain.tld\" - \"PGADMIN_DEFAULT_PASSWORD=S3cr3T\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_pgadmin.loadbalancer.server.port=80\" - \"traefik.http.routers.r_pgadmin.rule=Host(`pgadmin.domain.de`)\" - \"traefik.http.routers.r_pgadmin.entrypoints=websecure\" - \"traefik.http.routers.r_pgadmin.tls=true\" - \"traefik.http.routers.r_pgadmin.tls.certresolver=myresolver\" volumes : - \"/srv/main/pgadmin/servers.json:/pgadmin4/servers.json\" - \"/srv/main/pgadmin/storage:/var/lib/pgadmin/storage\" networks : - database - proxy Automatic Login \u00b6 You need to add the .pgpass file to /srv/main/pgadmin/storage/admin_domain.tld/.pgpass . Don't forget to adjust the permissions: chown -R 5050:5050 /srv/main/pgadmin/","title":"PostgreSQL"},{"location":"services/postgresql/#postgresql","text":"postgres documentation You can generate a database by setting the commented out environment variables. postgresql : image : postgres restart : always environment : - \"POSTGRES_PASSWORD=S3cr3T\" #- \"POSTGRES_DB=app\" volumes : - \"/srv/main/postgres/transfer:/transfer\" - \"/srv/main/postgres/data:/var/lib/postgresql/data\" networks : - database","title":"PostgreSQL"},{"location":"services/postgresql/#pgadmin-4","text":"pgadmin : image : dpage/pgadmin4 restart : always environment : - \"PGADMIN_DEFAULT_EMAIL=admin@domain.tld\" - \"PGADMIN_DEFAULT_PASSWORD=S3cr3T\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_pgadmin.loadbalancer.server.port=80\" - \"traefik.http.routers.r_pgadmin.rule=Host(`pgadmin.domain.de`)\" - \"traefik.http.routers.r_pgadmin.entrypoints=websecure\" - \"traefik.http.routers.r_pgadmin.tls=true\" - \"traefik.http.routers.r_pgadmin.tls.certresolver=myresolver\" volumes : - \"/srv/main/pgadmin/servers.json:/pgadmin4/servers.json\" - \"/srv/main/pgadmin/storage:/var/lib/pgadmin/storage\" networks : - database - proxy","title":"pgAdmin 4"},{"location":"services/postgresql/#automatic-login","text":"You need to add the .pgpass file to /srv/main/pgadmin/storage/admin_domain.tld/.pgpass . Don't forget to adjust the permissions: chown -R 5050:5050 /srv/main/pgadmin/","title":"Automatic Login"},{"location":"services/redis/","text":"redis documentation redis : image : redis restart : always command : \"redis-server --appendonly yes\" volumes : - \"/srv/main/redis:/data\" networks : - database","title":"Redis"},{"location":"services/sharelatex/","text":"ShareLaTeX requires a redis and a mongodb instance! paper : # use latest tag for setup, use your own image (tag: with-texlive-full) after installation image : sharelatex/sharelatex:latest restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_paper.loadbalancer.server.port=80\" - \"traefik.http.routers.r_paper.rule=Host(`paper.domain.de`)\" - \"traefik.http.routers.r_paper.entrypoints=websecure\" - \"traefik.http.routers.r_paper.tls.certresolver=myresolver\" volumes : - /srv/storage/paper/data:/var/lib/sharelatex environment : - \"SHARELATEX_APP_NAME=ShareLaTeX\" - \"SHARELATEX_MONGO_URL=mongodb://mongo/sharelatex\" - \"SHARELATEX_REDIS_HOST=redis\" - \"REDIS_HOST=redis\" - \"ENABLED_LINKED_FILE_TYPES=url,project_file\" - \"ENABLE_CONVERSIONS=true\" - \"EMAIL_CONFIRMATION_DISABLED=true\" - \"TEXMFVAR=/var/lib/sharelatex/tmp/texmf-var\" - \"SHARELATEX_SITE_URL=https://paper.domain.de\" - \"SHARELATEX_NAV_TITLE=ShareLaTeX\" - \"SHARELATEX_LEFT_FOOTER=[]\" - \"SHARELATEX_RIGHT_FOOTER=[]\" #- \"SHARELATEX_HEADER_IMAGE_URL=http://somewhere.com/mylogo.png\" #- \"SHARELATEX_EMAIL_FROM_ADDRESS=team@sharelatex.com\" #- \"SHARELATEX_EMAIL_SMTP_HOST=smtp.mydomain.com\" #- \"SHARELATEX_EMAIL_SMTP_PORT=587\" #- \"SHARELATEX_EMAIL_SMTP_SECURE=false\" #- \"SHARELATEX_EMAIL_SMTP_USER=\" #- \"SHARELATEX_EMAIL_SMTP_PASS=\" #- \"SHARELATEX_EMAIL_SMTP_TLS_REJECT_UNAUTH=true\" #- \"SHARELATEX_EMAIL_SMTP_IGNORE_TLS=false\" #- \"SHARELATEX_CUSTOM_EMAIL_FOOTER=This system is run by department x\" networks : - database - proxy # requirements for ShareLaTeX mongo : image : mongo:4.0 restart : always volumes : - \"/srv/storage/paper/mongo:/data/db\" healthcheck : test : echo 'db.stats().ok' | mongo localhost:27017/test --quiet interval : 10s timeout : 10s retries : 5 networks : - database redis : image : redis:5 restart : always volumes : - \"/srv/storage/paper/redis:/data\" networks : - database If you start the container using docker-compose, the image will be commited with all environment variables and labels. Install texlive-full Due to the fact, that this command will take a couple of house, I suggest you to execute it in a screen session. The Image will take about 8 gigabytes after installation all additional packages. screen -AmdS latex-installation \"docker-compose exec paper tlmgr update --self; tlmgr install scheme-full\" Save the current container filesystem as docker image with tag: with-texlive-full docker commit -m \"installing all latex packages\" $( docker-compose ps -q paper ) sharelatex/sharelatex:with-texlive-full Replace the image tag in your docker-compose.yml from latest to with-texlive-full Creating an user \u00b6 Now you have to create an admin user by simply running this command: docker-compose exec paper /bin/bash -c \"cd /var/www/sharelatex; grunt user:create-admin --email=my@email.address\" Replace my@email.address with your email. You will now be given a password reset link with which you can initially set the password for the admin user.","title":"ShareLaTeX"},{"location":"services/sharelatex/#creating-an-user","text":"Now you have to create an admin user by simply running this command: docker-compose exec paper /bin/bash -c \"cd /var/www/sharelatex; grunt user:create-admin --email=my@email.address\" Replace my@email.address with your email. You will now be given a password reset link with which you can initially set the password for the admin user.","title":"Creating an user"},{"location":"services/syncthing/","text":"Checkout the documentation syncthing: image: syncthing/syncthing restart: always volumes: - \"/srv/storage/syncthing:/var/syncthing\" ports: - \"22000:22000\" labels: - \"traefik.enable=true\" - \"traefik.http.services.srv_syncthing.loadbalancer.server.port=8384\" - \"traefik.http.routers.r_syncthing.rule=Host(`sync.domain.de`)\" - \"traefik.http.routers.r_syncthing.entrypoints=websecure\" - \"traefik.http.routers.r_syncthing.tls.certresolver=myresolver\" networks: - proxy","title":"Syncthing"},{"location":"services/teamspeak/","text":"Checkout the documentation ts3 : image : teamspeak restart : always environment : - \"TS3SERVER_DB_PLUGIN=ts3db_mariadb - \" TS3SERVER_DB_SQLCREATEPATH=create_mariadb - \"TS3SERVER_DB_HOST=mariadb\" - \"TS3SERVER_DB_USER=teamspeak\" - \"TS3SERVER_DB_PASSWORD=S3cr3t\" - \"TS3SERVER_DB_NAME=teamspeak\" - \"TS3SERVER_DB_WAITUNTILREADY=30\" - \"TS3SERVER_LICENSE=accept\" volumes : - \"/srv/main/ts3/data:/var/ts3server/\" ports : - '2008:2008' # accounting port - '2010:2010/udp' # weblist port - '9987:9987/udp' # default port (voice) - '30033:30033' # filetransfer port - '41144:41144' # tsdns port networks : - database - default sinusbot : image : sinusbot/docker restart : always labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_sinusbot.loadbalancer.server.port=8087\" - \"traefik.http.routers.r_sinusbot.rule=Host(`sinusbot.domain.de`)\" - \"traefik.http.routers.r_sinusbot.entrypoints=websecure\" - \"traefik.http.routers.r_sinusbot.tls=true\" - \"traefik.http.routers.r_sinusbot.tls.certresolver=myresolver\" volumes : - /srv/main/sinusbot/scripts:/opt/sinusbot/scripts - /srv/main/sinusbot/data:/opt/sinusbot/data networks : - proxy If you forgot your serverquery admin password you can reset it using the following command: If you configured the environment variables inside an env file you can use: --env-file .ts3server.env sudo docker run --rm -it \\ -e TS3SERVER_DB_PLUGIN=ts3db_mariadb \\ -e TS3SERVER_DB_SQLCREATEPATH=create_mariadb \\ -e TS3SERVER_DB_HOST=mariadb \\ -e TS3SERVER_DB_USER=teamspeak \\ -e TS3SERVER_DB_NAME=teamspeak \\ -e TS3SERVER_DB_PASSWORD=S3cr3t \\ -e TS3SERVER_DB_WAITUNTILREADY=30 \\ -e TS3SERVER_LICENSE=accept \\ -v \"/srv/main/ts3/data:/var/ts3server/\" \\ --network database \\ teamspeak \\ ts3server inifile=/var/run/ts3server/ts3server.ini serveradmin_password=NEW_PASSWORD Afterwards you can connect to port 10011 using telnet or netcat nc localhost 10011 login serveradmin NEW_PASSWORD # use server 1 (default) use 1 # add a new admin token tokenadd tokentype = 0 tokenid1 = 6 tokenid2 = 0","title":"Teamspeak 3 + Sinusbot"},{"location":"services/traefik/","text":"Traefik \u00b6 A reverse proxy is a router which binds to the ports 80 (http) and 443 (https). You can access the configured services by connecting to the proxy ( https://domain.tld ) with a specific host header, which is going to be evaluated by the proxy. But how do you connect to your proxy with this specific host header? Due to the fact that you configured your dns to redirect all subdomains to your server you can simply access https://phpmyadmin.domain.tld . You will reach the reverse proxy on port 443 with the host header phpmyadmin.domain.tld , after evaluation the proxy will redirect the incomming request to the configured service. Add the following configuration to your docker-compose.yml in the main stack: traefik : image : traefik:v2.4 command : - \"--api.insecure=true\" - \"--providers.docker=true\" - \"--providers.docker.exposedbydefault=false\" - \"--providers.docker.network=proxy\" - \"--entrypoints.web.address=:80\" - \"--entrypoints.web.http.redirections.entrypoint.to=websecure\" - \"--entrypoints.web.http.redirections.entrypoint.scheme=https\" - \"--entrypoints.websecure.address=:443\" - \"--certificatesresolvers.myresolver.acme.tlschallenge=true\" - \"--certificatesresolvers.myresolver.acme.email=admin@domain.de\" - \"--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json\" #- \"--certificatesresolvers.myresolver.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory\" - \"--providers.file.filename=/configs/dynamic.yml\" #- \"--log.level=DEBUG\" - \"--accesslog=true\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_traefik.loadbalancer.server.port=8080\" - \"traefik.http.routers.r_traefik.rule=Host(`traefik.domain.de`)\" - \"traefik.http.routers.r_traefik.entrypoints=websecure\" - \"traefik.http.routers.r_traefik.tls=true\" - \"traefik.http.routers.r_traefik.tls.certresolver=myresolver\" ports : - \"80:80\" - \"443:443\" volumes : - \"/srv/main/traefik/letsencrypt:/letsencrypt\" - \"/srv/main/traefik/dynamic.yml:/configs/dynamic.yml\" - \"/etc/localtime:/etc/localtime:ro\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" networks : - proxy Create the file /srv/main/traefik/dynamic.yml to require TLS version 1.2 or higher (currently only TLS 1.3): tls : options : default : minVersion : VersionTLS12 sniStrict : true cipherSuites : # TLS 1.3 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 - TLS_AES_128_GCM_SHA256 # TLS 1.2 - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 You also need a webserver for static content e.g. your error pages : static : image : nginx:stable-alpine restart : always labels : # BASIC CONFIGURATION - \"traefik.enable=true\" - \"traefik.http.services.srv_static.loadbalancer.server.port=80\" # ERROR PAGES - \"traefik.http.middlewares.error40x.errors.status=403-404\" - \"traefik.http.middlewares.error40x.errors.service=srv_static\" - \"traefik.http.middlewares.error40x.errors.query=/error/{status}.html\" - \"traefik.http.middlewares.error30x.errors.status=300-308\" - \"traefik.http.middlewares.error30x.errors.service=srv_static\" - \"traefik.http.middlewares.error30x.errors.query=/error/30x.html\" # HSTS - \"traefik.http.middlewares.mw_hsts.headers.frameDeny=true\" - \"traefik.http.middlewares.mw_hsts.headers.contentTypeNosniff=true\" - \"traefik.http.middlewares.mw_hsts.headers.browserXssFilter=true\" - \"traefik.http.middlewares.mw_hsts.headers.forceSTSHeader=true\" - \"traefik.http.middlewares.mw_hsts.headers.sslRedirect=true\" - \"traefik.http.middlewares.mw_hsts.headers.stsPreload=true\" - \"traefik.http.middlewares.mw_hsts.headers.stsSeconds=315360000\" - \"traefik.http.middlewares.mw_hsts.headers.stsIncludeSubdomains=true\" - \"traefik.http.middlewares.mw_hsts.headers.customRequestHeaders.X-Forwarded-Proto=https\" # DOMAIN ROOT CONTENT - \"traefik.http.routers.r_static_root.rule=HostRegexp(`domain.de`, `{subdomain:[a-z0-9]+}.domain.de`)\" - \"traefik.http.routers.r_static_root.entrypoints=websecure\" - \"traefik.http.routers.r_static_root.tls=true\" - \"traefik.http.routers.r_static_root.tls.certresolver=myresolver\" - \"traefik.http.routers.r_static_root.priority=10\" - \"traefik.http.middlewares.mw_static_root.addprefix.prefix=/domain_root/\" - \"traefik.http.routers.r_static_root.middlewares=mw_hsts@docker,mw_static_root@docker,error40x@docker,error30x@docker\" volumes : - \"/srv/main/static/webroot:/usr/share/nginx/html/\" networks : - proxy You should also add your domain to the HSTS Preload List , all subdomains need to be reachable using a secure connection, so you need a wildcard certificate for this. Let's do a ssltest to see how good we are: Wildcard Certificates \u00b6 Modify the command section of your traefik, to setup dnschallenge (remove ....tlschallenge=true ): # e.g. for cloudflare - \"--certificatesresolvers.myresolver.acme.dnschallenge=true\" - \"--certificatesresolvers.myresolver.acme.dnschallenge.provider=cloudflare\" - \"--certificatesresolvers.myresolver.acme.dnschallenge.resolvers=1.1.1.1:53,8.8.8.8:53\" Modify the environment section ( you can also use docker secrets ) of your traefik, to provide the required credentials for you dns api (checkout the list of providers ). Configure the wildcard certificate for your services (e.g. the traefik dashboard in the labels section of the traefik service): - \"traefik.http.routers.r_traefik.tls.domains[0].main=domain.de\" - \"traefik.http.routers.r_traefik.tls.domains[0].sans=*.domain.de\" Authentication Middlewares \u00b6 Traefik offers a lot of authentication middlewares (e.g. BasicAuth , ForwardAuth (if you can provide a authentication service)) Basic Auth \u00b6 We are going to add a new router to our static service, which will provide files for download, behind an basic auth. First we have to extend our traefik service, with the htpasswd file for the service. This can be done by simply adding the following volume: ... volumes : ... - \"/srv/main/traefik/webfiles.htpasswd:/htpasswd/webfiles\" ... ... You can create the htpasswd file using the htpasswd utility from the apache2-utils package (at least on debian based operating systems). apt install -y apache2-utils htpasswd -c /srv/main/traefik/webfiles.htpasswd -c <username> Now we can add the new router to our static service: ... labels : ... - \"traefik.http.routers.r_static_files.rule=Host(`files.domain.de`)\" - \"traefik.http.routers.r_static_files.entrypoints=websecure\" - \"traefik.http.routers.r_static_files.tls=true\" - \"traefik.http.routers.r_static_files.tls.certresolver=myresolver\" - \"traefik.http.middlewares.mw_static_files.addprefix.prefix=/static_files/\" - \"traefik.http.middlewares.mw_static_files_auth.basicauth.usersfile=/htpasswd/webfiles\" - \"traefik.http.routers.r_static_files.middlewares=mw_static_files@docker,mw_static_files_auth@docker,error40x@docker,error30x@docker\" ... We also need to enable directory listing by creating the configuration for this uri: server { listen 80 ; server_name localhost ; location / { root /usr/share/nginx/html ; index index.html index.htm ; } location /static_files { root /usr/share/nginx/html ; autoindex on ; } } Don't forget to add the created configuration to the volume section of the static service: ... volumes : ... - \"/srv/main/static/nginx.conf:/etc/nginx/conf.d/default.conf\" ... Redirect Middleware \u00b6 You can also redirect a domain directly to another resource (e.g. your external webinterface of your mailserver): - \"traefik.http.routers.r_redirect.rule=Host(`domain.de`)\" - \"traefik.http.routers.r_redirect.entrypoints=websecure\" - \"traefik.http.routers.r_redirect.tls=true\" - \"traefik.http.routers.r_redirect.tls.certresolver=myresolver\" - \"traefik.http.middlewares.mw_redirect.redirectregex.regex=https://domain.de\" - \"traefik.http.middlewares.mw_redirect.redirectregex.replacement=https://redirecteddomain.de\" - \"traefik.http.middlewares.mw_redirect.redirectregex.permanent=true\" - \"traefik.http.routers.r_redirect.middlewares=mw_redirect@docker,error40x@docker,error30x@docker\"","title":"Traefik"},{"location":"services/traefik/#traefik","text":"A reverse proxy is a router which binds to the ports 80 (http) and 443 (https). You can access the configured services by connecting to the proxy ( https://domain.tld ) with a specific host header, which is going to be evaluated by the proxy. But how do you connect to your proxy with this specific host header? Due to the fact that you configured your dns to redirect all subdomains to your server you can simply access https://phpmyadmin.domain.tld . You will reach the reverse proxy on port 443 with the host header phpmyadmin.domain.tld , after evaluation the proxy will redirect the incomming request to the configured service. Add the following configuration to your docker-compose.yml in the main stack: traefik : image : traefik:v2.4 command : - \"--api.insecure=true\" - \"--providers.docker=true\" - \"--providers.docker.exposedbydefault=false\" - \"--providers.docker.network=proxy\" - \"--entrypoints.web.address=:80\" - \"--entrypoints.web.http.redirections.entrypoint.to=websecure\" - \"--entrypoints.web.http.redirections.entrypoint.scheme=https\" - \"--entrypoints.websecure.address=:443\" - \"--certificatesresolvers.myresolver.acme.tlschallenge=true\" - \"--certificatesresolvers.myresolver.acme.email=admin@domain.de\" - \"--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json\" #- \"--certificatesresolvers.myresolver.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory\" - \"--providers.file.filename=/configs/dynamic.yml\" #- \"--log.level=DEBUG\" - \"--accesslog=true\" labels : - \"traefik.enable=true\" - \"traefik.http.services.srv_traefik.loadbalancer.server.port=8080\" - \"traefik.http.routers.r_traefik.rule=Host(`traefik.domain.de`)\" - \"traefik.http.routers.r_traefik.entrypoints=websecure\" - \"traefik.http.routers.r_traefik.tls=true\" - \"traefik.http.routers.r_traefik.tls.certresolver=myresolver\" ports : - \"80:80\" - \"443:443\" volumes : - \"/srv/main/traefik/letsencrypt:/letsencrypt\" - \"/srv/main/traefik/dynamic.yml:/configs/dynamic.yml\" - \"/etc/localtime:/etc/localtime:ro\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" networks : - proxy Create the file /srv/main/traefik/dynamic.yml to require TLS version 1.2 or higher (currently only TLS 1.3): tls : options : default : minVersion : VersionTLS12 sniStrict : true cipherSuites : # TLS 1.3 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 - TLS_AES_128_GCM_SHA256 # TLS 1.2 - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 You also need a webserver for static content e.g. your error pages : static : image : nginx:stable-alpine restart : always labels : # BASIC CONFIGURATION - \"traefik.enable=true\" - \"traefik.http.services.srv_static.loadbalancer.server.port=80\" # ERROR PAGES - \"traefik.http.middlewares.error40x.errors.status=403-404\" - \"traefik.http.middlewares.error40x.errors.service=srv_static\" - \"traefik.http.middlewares.error40x.errors.query=/error/{status}.html\" - \"traefik.http.middlewares.error30x.errors.status=300-308\" - \"traefik.http.middlewares.error30x.errors.service=srv_static\" - \"traefik.http.middlewares.error30x.errors.query=/error/30x.html\" # HSTS - \"traefik.http.middlewares.mw_hsts.headers.frameDeny=true\" - \"traefik.http.middlewares.mw_hsts.headers.contentTypeNosniff=true\" - \"traefik.http.middlewares.mw_hsts.headers.browserXssFilter=true\" - \"traefik.http.middlewares.mw_hsts.headers.forceSTSHeader=true\" - \"traefik.http.middlewares.mw_hsts.headers.sslRedirect=true\" - \"traefik.http.middlewares.mw_hsts.headers.stsPreload=true\" - \"traefik.http.middlewares.mw_hsts.headers.stsSeconds=315360000\" - \"traefik.http.middlewares.mw_hsts.headers.stsIncludeSubdomains=true\" - \"traefik.http.middlewares.mw_hsts.headers.customRequestHeaders.X-Forwarded-Proto=https\" # DOMAIN ROOT CONTENT - \"traefik.http.routers.r_static_root.rule=HostRegexp(`domain.de`, `{subdomain:[a-z0-9]+}.domain.de`)\" - \"traefik.http.routers.r_static_root.entrypoints=websecure\" - \"traefik.http.routers.r_static_root.tls=true\" - \"traefik.http.routers.r_static_root.tls.certresolver=myresolver\" - \"traefik.http.routers.r_static_root.priority=10\" - \"traefik.http.middlewares.mw_static_root.addprefix.prefix=/domain_root/\" - \"traefik.http.routers.r_static_root.middlewares=mw_hsts@docker,mw_static_root@docker,error40x@docker,error30x@docker\" volumes : - \"/srv/main/static/webroot:/usr/share/nginx/html/\" networks : - proxy You should also add your domain to the HSTS Preload List , all subdomains need to be reachable using a secure connection, so you need a wildcard certificate for this. Let's do a ssltest to see how good we are:","title":"Traefik"},{"location":"services/traefik/#wildcard-certificates","text":"Modify the command section of your traefik, to setup dnschallenge (remove ....tlschallenge=true ): # e.g. for cloudflare - \"--certificatesresolvers.myresolver.acme.dnschallenge=true\" - \"--certificatesresolvers.myresolver.acme.dnschallenge.provider=cloudflare\" - \"--certificatesresolvers.myresolver.acme.dnschallenge.resolvers=1.1.1.1:53,8.8.8.8:53\" Modify the environment section ( you can also use docker secrets ) of your traefik, to provide the required credentials for you dns api (checkout the list of providers ). Configure the wildcard certificate for your services (e.g. the traefik dashboard in the labels section of the traefik service): - \"traefik.http.routers.r_traefik.tls.domains[0].main=domain.de\" - \"traefik.http.routers.r_traefik.tls.domains[0].sans=*.domain.de\"","title":"Wildcard Certificates"},{"location":"services/traefik/#authentication-middlewares","text":"Traefik offers a lot of authentication middlewares (e.g. BasicAuth , ForwardAuth (if you can provide a authentication service))","title":"Authentication Middlewares"},{"location":"services/traefik/#basic-auth","text":"We are going to add a new router to our static service, which will provide files for download, behind an basic auth. First we have to extend our traefik service, with the htpasswd file for the service. This can be done by simply adding the following volume: ... volumes : ... - \"/srv/main/traefik/webfiles.htpasswd:/htpasswd/webfiles\" ... ... You can create the htpasswd file using the htpasswd utility from the apache2-utils package (at least on debian based operating systems). apt install -y apache2-utils htpasswd -c /srv/main/traefik/webfiles.htpasswd -c <username> Now we can add the new router to our static service: ... labels : ... - \"traefik.http.routers.r_static_files.rule=Host(`files.domain.de`)\" - \"traefik.http.routers.r_static_files.entrypoints=websecure\" - \"traefik.http.routers.r_static_files.tls=true\" - \"traefik.http.routers.r_static_files.tls.certresolver=myresolver\" - \"traefik.http.middlewares.mw_static_files.addprefix.prefix=/static_files/\" - \"traefik.http.middlewares.mw_static_files_auth.basicauth.usersfile=/htpasswd/webfiles\" - \"traefik.http.routers.r_static_files.middlewares=mw_static_files@docker,mw_static_files_auth@docker,error40x@docker,error30x@docker\" ... We also need to enable directory listing by creating the configuration for this uri: server { listen 80 ; server_name localhost ; location / { root /usr/share/nginx/html ; index index.html index.htm ; } location /static_files { root /usr/share/nginx/html ; autoindex on ; } } Don't forget to add the created configuration to the volume section of the static service: ... volumes : ... - \"/srv/main/static/nginx.conf:/etc/nginx/conf.d/default.conf\" ...","title":"Basic Auth"},{"location":"services/traefik/#redirect-middleware","text":"You can also redirect a domain directly to another resource (e.g. your external webinterface of your mailserver): - \"traefik.http.routers.r_redirect.rule=Host(`domain.de`)\" - \"traefik.http.routers.r_redirect.entrypoints=websecure\" - \"traefik.http.routers.r_redirect.tls=true\" - \"traefik.http.routers.r_redirect.tls.certresolver=myresolver\" - \"traefik.http.middlewares.mw_redirect.redirectregex.regex=https://domain.de\" - \"traefik.http.middlewares.mw_redirect.redirectregex.replacement=https://redirecteddomain.de\" - \"traefik.http.middlewares.mw_redirect.redirectregex.permanent=true\" - \"traefik.http.routers.r_redirect.middlewares=mw_redirect@docker,error40x@docker,error30x@docker\"","title":"Redirect Middleware"}]}